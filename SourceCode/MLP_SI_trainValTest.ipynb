{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################################################\n",
    "# Audio-driven upper-body motion synthesis on a humanoid robot\n",
    "# Computer Science Tripos Part III Project\n",
    "# Jan Ondras (jo356@cam.ac.uk), Trinity College, University of Cambridge\n",
    "# 2017/18\n",
    "#####################################################################################\n",
    "# Training, validation and testing of the MLP-SI model\n",
    "#####################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################################################################\n",
    "# Baseline MLP (assuming independence between timesteps)\n",
    "# Subject-independent\n",
    "# Training set is shuffled (by Keras)\n",
    "#######################################################################################################\n",
    "# VALIDATION / ARCHITECTURE TUNING\n",
    "# DONE\n",
    "#######################################################################################################\n",
    "import numpy as np\n",
    "import time\n",
    "import glob\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.callbacks import EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from geoutils import radToDeg, degToRad\n",
    "from evalutils import norm_Y, inv_norm_Y, eval_test, plot_predictions\n",
    "from settings import *\n",
    "\n",
    "AF_type = 'AF_logFB26_norm'\n",
    "AF_type = 'AF_logFB52_norm' # SET tuning_type\n",
    "AF_type = 'AF_logFB78_norm'\n",
    "# AF_type = 'AF_MFCC13_norm'\n",
    "\n",
    "TE_folder = 'TrainingExamples_16kHz'\n",
    "\n",
    "# XXX prefix means NO DROPOUT\n",
    "save_results_path_prefix = './../Dataset/'+TE_folder+'/Results/MLP_SI/XXX'\n",
    "\n",
    "FPS = 100.\n",
    "\n",
    "#######################################################################################################\n",
    "np.random.seed(37) # for reproducibility\n",
    "\n",
    "unique_srt_VIDs = np.load('./../Dataset/'+TE_folder+'/te_unique_srt_VIDs.npz')['unique_srt_VIDs'] # sorted VIDs\n",
    "all_srt_VIDs = np.load('./../Dataset/'+TE_folder+'/te_VIDs.npz')['VIDs']\n",
    "unique_srt_SIDs = np.array([x[:5] for i, x in enumerate(unique_srt_VIDs) if i % 2 == 0]) # ['PID02', 'PID05', ..\n",
    "\n",
    "AF = np.load('./../Dataset/'+TE_folder+'/te_'+AF_type+'.npz')[AF_type]\n",
    "N_features = AF.shape[1]\n",
    "PF = np.load('./../Dataset/'+TE_folder+'/te_PF_smooth_LPBF_4.0.npz')['PF_smooth_LPBF']\n",
    "PF = PF[:, :11]\n",
    "N_targets = PF.shape[1]\n",
    "\n",
    "#######################\n",
    "# Target (Y) normalisation, into range 0-1 according to constraints\n",
    "PF = norm_Y(PF)\n",
    "print \"Targets (Y) are TRANSFORMED to 0-1 range\"\n",
    "\n",
    "#######################\n",
    "# Load the dataset split  \n",
    "ds = np.load('./../Dataset/'+TE_folder+'/Dataset_split/split_masks_all.npz')\n",
    "train_mask = ds['train_mask']\n",
    "val_mask   = ds['val_mask']\n",
    "test_mask  = ds['test_mask']\n",
    "\n",
    "X_train = AF[train_mask]\n",
    "X_val   = AF[val_mask]\n",
    "X_test  = AF[test_mask]\n",
    "del AF\n",
    "Y_train = PF[train_mask]\n",
    "Y_val   = PF[val_mask]\n",
    "Y_test  = PF[test_mask]\n",
    "del PF\n",
    "\n",
    "#######################\n",
    "# Learning settings\n",
    "epochs = 1000\n",
    "N_runs = 1\n",
    "dropout = 0.\n",
    "\n",
    "# Architectures to try\n",
    "N_hl_range = [1, 2, 3, 5, 7] # range of numbers of hidden layers\n",
    "N_hu_range = [8, 16, 32, 64, 128, 256, 512] # range of numbers of units per hidden layer\n",
    "\n",
    "print \"Validation over \", len(N_hl_range) * len(N_hu_range), \"=\", len(N_hl_range), \"x\", len(N_hu_range), \"parameter settings\"\n",
    "\n",
    "tuning_type = str(N_runs) + '_' + str(len(N_hl_range)*len(N_hu_range)) + '_AF' + AF_type.split('_')[1][-2:]\n",
    "\n",
    "print TE_folder, AF_type, tuning_type\n",
    "if tuning_type[-2:] != AF_type.split('_')[1][-2:]:\n",
    "    raise ValueError(\"Tuning type and audio feature type mismatch!\")\n",
    "\n",
    "#######################\n",
    "# Validation\n",
    "train_batch_size = len(X_train)\n",
    "val_batch_size = len(X_val)\n",
    "test_batch_size = len(X_test)\n",
    "\n",
    "vals = np.zeros((len(N_hl_range), len(N_hu_range)))\n",
    "vals_std = np.zeros((len(N_hl_range), len(N_hu_range)))\n",
    "\n",
    "st = time.time()\n",
    "for a, N_hl in enumerate(N_hl_range):\n",
    "    for b, N_hu in enumerate(N_hu_range):\n",
    "        print \"HL, HU: \", N_hl, N_hu\n",
    "        #st = time.time()\n",
    "        # Create model\n",
    "        model = Sequential()\n",
    "        model.add(Dense(N_hu, activation='relu', kernel_initializer='he_uniform', input_dim=N_features))\n",
    "        #model.add(Dropout(dropout))\n",
    "        for i in range(1, N_hl):\n",
    "            model.add(Dense(N_hu, activation='relu', kernel_initializer='he_uniform'))\n",
    "            #model.add(Dropout(dropout))\n",
    "        model.add(Dense(N_targets, activation='sigmoid'))\n",
    "\n",
    "        model.compile(loss='mean_squared_error', optimizer=Adam())\n",
    "        #print model.summary()\n",
    "        early_stop = EarlyStopping(monitor='val_loss', patience=10, verbose=1) # stop after 10 epochs without improvement in val_loss\n",
    "\n",
    "        vals_actual = []\n",
    "        for i in range(N_runs):\n",
    "            model.fit(X_train, Y_train, epochs=epochs, batch_size=train_batch_size, \n",
    "                       validation_data = (X_val, Y_val), verbose=0, callbacks=[early_stop])\n",
    "\n",
    "            vals_actual.append( model.evaluate(X_val, Y_val, batch_size=val_batch_size, verbose=0) )\n",
    "\n",
    "        vals[a][b] = np.mean(vals_actual)\n",
    "        vals_std[a][b] = np.std(vals_actual)\n",
    "        print \"\\tTime taken: \", time.time()-st, (time.time()-st)/60. \n",
    "\n",
    "best_N_hl = N_hl_range[np.argmin(vals) // len(N_hu_range)]\n",
    "best_N_hu = N_hu_range[np.argmin(vals) % len(N_hu_range)]\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(vals.T, cmap=cmap) # , vmax = 0.6 , cmap=cmap\n",
    "plt.xticks(range(len(N_hl_range)), N_hl_range)\n",
    "plt.yticks(range(len(N_hu_range)), N_hu_range)\n",
    "plt.xlabel('# hidden layers')\n",
    "plt.ylabel('# hidden units per leayer')\n",
    "plt.colorbar(orientation=\"horizontal\", fraction=0.027)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print \"\\tOptimal number of hidden layers / hidden units: \", best_N_hl, \" / \", best_N_hu\n",
    "print \"\\tBest validation MSE: \", np.min(vals), vals[np.argmin(vals) // len(N_hu_range), np.argmin(vals) % len(N_hu_range)], vals.shape, np.argmin(vals)\n",
    "\n",
    "# Save results\n",
    "np.savez(save_results_path_prefix + 'val_' + tuning_type + '.npz', \n",
    "        vals=vals, vals_std=vals_std, best_N_hl=best_N_hl, best_N_hu=best_N_hu, \n",
    "        N_hl_range=N_hl_range, N_hu_range=N_hu_range, N_runs=N_runs, dropout=dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################################################################\n",
    "# Show validation results\n",
    "#######################################################################################################\n",
    "import numpy as np\n",
    "import time\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LogNorm\n",
    "from settings import *\n",
    "\n",
    "# # tuning_type = '1_35'\n",
    "# tuning_type = '1_18'\n",
    "\n",
    "# # tuning_type = '1_35_AF52'\n",
    "# tuning_type = '1_18_AF52'\n",
    "\n",
    "# # tuning_type = '1_35_AF78'\n",
    "# tuning_type = '1_18_AF78'\n",
    "\n",
    "tuning_types = [\n",
    "    '1_35_AF13',\n",
    "    '1_35_AF26', \n",
    "    '1_35_AF52', \n",
    "    '1_35_AF78'\n",
    "]\n",
    "\n",
    "TE_folder = 'TrainingExamples_16kHz'\n",
    "save_results_path_prefix = './../Dataset/'+TE_folder+'/Results/MLP_SI/XXX'\n",
    "\n",
    "for tuning_type in tuning_types:\n",
    "    print tuning_type\n",
    "\n",
    "    dd = np.load(save_results_path_prefix + 'val_' + tuning_type + '.npz')\n",
    "    vals = dd['vals']\n",
    "    vals_std = dd['vals_std']\n",
    "\n",
    "    best_N_hl = int(dd['best_N_hl'])\n",
    "    best_N_hu = int(dd['best_N_hu'])\n",
    "    N_hl_range = dd['N_hl_range']\n",
    "    N_hu_range = dd['N_hu_range']\n",
    "\n",
    "    print \"Validation over \", len(N_hl_range) * len(N_hu_range), \"=\", len(N_hl_range), \"x\", len(N_hu_range), \"parameter settings\"\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.imshow(vals.T, cmap=cmap, \n",
    "               #norm=LogNorm(vmin=vals.min(), vmax=vals.max())\n",
    "              ) # , vmax = 0.6 , cmap=cmap\n",
    "    plt.xticks(range(len(N_hl_range)), N_hl_range)\n",
    "    plt.yticks(range(len(N_hu_range)), N_hu_range)\n",
    "    plt.xlabel('# hidden layers')\n",
    "    plt.ylabel('# hidden units per leayer')\n",
    "    plt.colorbar(orientation=\"vertical\", fraction=0.049)\n",
    "#     plt.colorbar(orientation=\"horizontal\", fraction=0.027)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    #print vals.T\n",
    "\n",
    "    print \"\\tOptimal number of hidden layers / hidden units: \", best_N_hl, \" / \", best_N_hu\n",
    "    print \"\\tBest validation MSE: \", np.min(vals), vals[np.argmin(vals) // len(N_hu_range), np.argmin(vals) % len(N_hu_range)], vals.shape, np.argmin(vals)\n",
    "    print \"===================================================================================\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################################################################\n",
    "# TRAIN (using best architecture) \n",
    "# & EVALUATE ON VALIDATION SET: COMPARE 4 FEATURE SETS\n",
    "# & EVALUATE ON TESTING SET (for logFB26 only)\n",
    "# Saving 4 models, for each feature set\n",
    "# DONE\n",
    "#######################################################################################################\n",
    "import numpy as np\n",
    "import time\n",
    "import glob\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from geoutils import radToDeg, degToRad\n",
    "from evalutils import get_global_cca, get_local_cca, eval_test, norm_Y, inv_norm_Y, plot_predictions\n",
    "\n",
    "SEGMENT_LEN = 300 # for evaluation (local cca)\n",
    "\n",
    "tuning_types = [\n",
    "    '1_35_AF13',\n",
    "    '1_35_AF26', \n",
    "    '1_35_AF52', \n",
    "    '1_35_AF78'\n",
    "]\n",
    "AF_types = [\n",
    "    'AF_MFCC13_norm',\n",
    "    'AF_logFB26_norm',\n",
    "    'AF_logFB52_norm',\n",
    "    'AF_logFB78_norm'\n",
    "]\n",
    "\n",
    "TE_folder = 'TrainingExamples_16kHz'\n",
    "save_results_path_prefix = './../Dataset/'+TE_folder+'/Results/MLP_SI/XXX'\n",
    "model_checkpoint_path_prefix = './ModelCheckpoints/MLP_SI/'\n",
    "\n",
    "np.random.seed(37) # for reproducibility\n",
    "unique_srt_VIDs = unique_srt_VIDs = np.load('./../Dataset/'+TE_folder+'/te_unique_srt_VIDs.npz')['unique_srt_VIDs'] # sorted VIDs\n",
    "all_srt_VIDs = np.load('./../Dataset/'+TE_folder+'/te_VIDs.npz')['VIDs']\n",
    "unique_srt_SIDs = np.array([x[:5] for i, x in enumerate(unique_srt_VIDs) if i % 2 == 0]) # ['PID02', 'PID05', ..\n",
    "PF = np.load('./../Dataset/'+TE_folder+'/te_PF_smooth_LPBF_4.0.npz')['PF_smooth_LPBF']\n",
    "PF = PF[:, :11]\n",
    "N_targets = PF.shape[1]\n",
    "###########\n",
    "# Target (Y) normalisation, into range 0-1 according to constraints\n",
    "PF = norm_Y(PF)\n",
    "print \"Targets (Y) are TRANSFORMED to 0-1 range\"\n",
    "\n",
    "#######################\n",
    "# Load the dataset split  \n",
    "ds = np.load('./../Dataset/'+TE_folder+'/Dataset_split/split_masks_all.npz')\n",
    "train_mask = ds['train_mask']\n",
    "val_mask   = ds['val_mask']\n",
    "val_VIDs  = ds['val_VIDs']\n",
    "val_VIDs_ind_cnts = ds['val_VIDs_ind_cnts']\n",
    "test_mask  = ds['test_mask']\n",
    "test_VIDs  = ds['test_VIDs']\n",
    "test_VIDs_ind_cnts = ds['test_VIDs_ind_cnts']\n",
    "\n",
    "Y_train = PF[train_mask]\n",
    "Y_val   = PF[val_mask]\n",
    "Y_test  = PF[test_mask]\n",
    "\n",
    "FPS = 100.\n",
    "\n",
    "# Learning settings\n",
    "epochs = 1000\n",
    "dropout = 0.\n",
    "\n",
    "st = time.time()\n",
    "\n",
    "for tuning_type, AF_type in zip(tuning_types, AF_types):\n",
    "    \n",
    "    print \"Saving BEST model at:\", model_checkpoint_path_prefix + tuning_type + '/'\n",
    "\n",
    "    print TE_folder, AF_type, tuning_type\n",
    "    if tuning_type[-2:] != AF_type.split('_')[1][-2:]:\n",
    "        raise ValueError(\"Tuning type and audio feature type mismatch!\")\n",
    "\n",
    "    #######################################################################################################\n",
    "    AF = np.load('./../Dataset/'+TE_folder+'/te_'+AF_type+'.npz')[AF_type]\n",
    "    N_features = AF.shape[1]\n",
    "\n",
    "    X_train = AF[train_mask]\n",
    "    X_val   = AF[val_mask]\n",
    "    X_test  = AF[test_mask]\n",
    "    del AF\n",
    "\n",
    "    #######################\n",
    "    # Load validation data\n",
    "    dd = np.load(save_results_path_prefix + 'val_' + tuning_type + '.npz')\n",
    "    best_N_hl = int(dd['best_N_hl'])\n",
    "    best_N_hu = int(dd['best_N_hu'])    \n",
    "    print \"\\tOptimal number of hidden layers / hidden units: \", best_N_hl, \" / \", best_N_hu\n",
    "\n",
    "    train_batch_size = len(X_train)\n",
    "    val_batch_size = len(X_val)\n",
    "    test_batch_size = len(X_test)\n",
    "\n",
    "    ##########################\n",
    "    # Final train & test\n",
    "\n",
    "    # Create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(best_N_hu, activation='relu', kernel_initializer='he_uniform', input_dim=N_features))\n",
    "    #model.add(Dropout(dropout))\n",
    "    for i in range(1, best_N_hl):\n",
    "        model.add(Dense(best_N_hu, activation='relu', kernel_initializer='he_uniform'))\n",
    "        #model.add(Dropout(dropout))\n",
    "    model.add(Dense(N_targets, activation='sigmoid'))\n",
    "\n",
    "    model.compile(loss='mean_squared_error', optimizer=Adam())\n",
    "    print model.summary()\n",
    "    print \"#parameters: \", model.count_params()\n",
    "    \n",
    "    early_stop = EarlyStopping(monitor='val_loss', patience=10, verbose=1) # stop after 10 epochs without improvement in val_acc\n",
    "\n",
    "    # Checkpoint model weights and the model itself: at each epoch\n",
    "    model_checkpoint_name = 'm_{epoch:04d}_{loss:.4f}_{val_loss:.4f}.hdf5'\n",
    "    model_checkpoint = ModelCheckpoint(model_checkpoint_path_prefix + tuning_type + '/' + model_checkpoint_name, monitor='val_loss', \n",
    "                                       verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "\n",
    "    hist = model.fit(X_train, Y_train, epochs=epochs, batch_size=train_batch_size, \n",
    "               validation_data = (X_val, Y_val), verbose=1, callbacks=[early_stop, model_checkpoint])\n",
    "\n",
    "    print \"\\tTime taken: \", time.time()-st, (time.time()-st)/60. \n",
    "\n",
    "    ###############################################################################################################\n",
    "    # Evaluate on validation set\n",
    "    Y_val_pred = model.predict(X_val, batch_size=val_batch_size, verbose=1)\n",
    "\n",
    "    # Save results: predictions will be saved in radians; for generation on robot\n",
    "    # Raw and smoothed (low-pass 4Hz)\n",
    "    from postprocessingutils import save_predictions_and_eval\n",
    "    save_predictions_and_eval(save_results_path_prefix + 'MSvaltest_' + tuning_type, \n",
    "                     X_val, Y_val, Y_val_pred, 'MLP_SI', SEGMENT_LEN, val_VIDs, val_VIDs_ind_cnts, \n",
    "                             N_params=model.count_params(), N_epochs=len(hist.history['loss']))\n",
    "    \n",
    "    ###############################################################################################################\n",
    "    # Evaluate on testing set: only for 1_35_AF26\n",
    "    if tuning_type == '1_35_AF26':\n",
    "        Y_test_pred = model.predict(X_test, batch_size=test_batch_size, verbose=1)\n",
    "\n",
    "        # Save results: predictions will be saved in radians; for generation on robot\n",
    "        # Raw and smoothed (low-pass 4Hz)\n",
    "        from postprocessingutils import save_predictions_and_eval\n",
    "        save_predictions_and_eval(save_results_path_prefix + 'MStest_' + tuning_type, \n",
    "                         X_test, Y_test, Y_test_pred, 'MLP_SI', SEGMENT_LEN, test_VIDs, test_VIDs_ind_cnts, \n",
    "                                 N_params=model.count_params(), N_epochs=len(hist.history['loss']))    \n",
    "    \n",
    "    print \"\\tTime taken: \", time.time()-st, (time.time()-st)/60. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################################################################\n",
    "# Re-Evaluate on VALIDATION & TEST SET using BEST MODEL\n",
    "# DONE\n",
    "#######################################################################################################\n",
    "import numpy as np\n",
    "import time\n",
    "import glob\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.callbacks import EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from geoutils import radToDeg, degToRad\n",
    "from evalutils import norm_Y, inv_norm_Y, eval_test, plot_predictions\n",
    "from settings import *\n",
    "\n",
    "from keras.models import load_model\n",
    "\n",
    "tuning_types = [\n",
    "    '1_35_AF13',\n",
    "    '1_35_AF26', \n",
    "    '1_35_AF52', \n",
    "    '1_35_AF78'\n",
    "]\n",
    "AF_types = [\n",
    "    'AF_MFCC13_norm',\n",
    "    'AF_logFB26_norm',\n",
    "    'AF_logFB52_norm',\n",
    "    'AF_logFB78_norm'\n",
    "]\n",
    "model_names = [\n",
    "    'm_1000_0.0141_0.0183.hdf5', \n",
    "    'm_0360_0.0143_0.0184.hdf5',\n",
    "    'm_0903_0.0139_0.0185.hdf5',\n",
    "    'm_0667_0.0140_0.0182.hdf5'\n",
    "]\n",
    "\n",
    "TE_folder = 'TrainingExamples_16kHz'\n",
    "save_results_path_prefix = './../Dataset/'+TE_folder+'/Results/MLP_SI/XXX'\n",
    "model_checkpoint_path_prefix = './ModelCheckpoints/MLP_SI/'\n",
    "\n",
    "PF = np.load('./../Dataset/'+TE_folder+'/te_PF_smooth_LPBF_4.0.npz')['PF_smooth_LPBF']\n",
    "PF = PF[:, :11]\n",
    "N_targets = PF.shape[1]\n",
    "###########\n",
    "# Target (Y) normalisation, into range 0-1 according to constraints\n",
    "PF = norm_Y(PF)\n",
    "print \"Targets (Y) are TRANSFORMED to 0-1 range\"\n",
    "\n",
    "#######################\n",
    "# Load the dataset split  \n",
    "ds = np.load('./../Dataset/'+TE_folder+'/Dataset_split/split_masks_all.npz')\n",
    "val_mask   = ds['val_mask']\n",
    "val_VIDs  = ds['val_VIDs']\n",
    "val_VIDs_ind_cnts = ds['val_VIDs_ind_cnts']\n",
    "test_mask  = ds['test_mask']\n",
    "test_VIDs  = ds['test_VIDs']\n",
    "test_VIDs_ind_cnts = ds['test_VIDs_ind_cnts']\n",
    "\n",
    "Y_val   = PF[val_mask]\n",
    "Y_test  = PF[test_mask]\n",
    "st = time.time()\n",
    "for tuning_type, AF_type, model_name in zip(tuning_types, AF_types, model_names):\n",
    "       \n",
    "    print TE_folder, AF_type, tuning_type\n",
    "    if tuning_type[-2:] != AF_type.split('_')[1][-2:]:\n",
    "        raise ValueError(\"Tuning type and audio feature type mismatch!\")\n",
    "\n",
    "    #######################################################################################################\n",
    "    AF = np.load('./../Dataset/'+TE_folder+'/te_'+AF_type+'.npz')[AF_type]\n",
    "    N_features = AF.shape[1]\n",
    "    X_val   = AF[val_mask]\n",
    "    X_test  = AF[test_mask]\n",
    "    del AF\n",
    "    \n",
    "    val_batch_size = len(X_val)\n",
    "    test_batch_size = len(X_test)\n",
    "\n",
    "    #######################\n",
    "    # Load best model\n",
    "    test_model_name = model_checkpoint_path_prefix + tuning_type + '/' + model_name\n",
    "    print \"Loading BEST model from:\", test_model_name\n",
    "    model = load_model(test_model_name)\n",
    "    \n",
    "    \n",
    "    ###############################################################################################################\n",
    "    # Evaluate on validation set\n",
    "    Y_val_pred = model.predict(X_val, batch_size=val_batch_size, verbose=1)\n",
    "\n",
    "    # Save results: predictions will be saved in radians; for generation on robot\n",
    "    # Raw and smoothed (low-pass 4Hz)\n",
    "    from postprocessingutils import save_predictions_and_eval\n",
    "    save_predictions_and_eval(save_results_path_prefix + 'MSBMvaltest_' + tuning_type, \n",
    "                     X_val, Y_val, Y_val_pred, 'MLP_SI', SEGMENT_LEN, val_VIDs, val_VIDs_ind_cnts, \n",
    "                             N_params=model.count_params())\n",
    "    \n",
    "    ###############################################################################################################\n",
    "    # Evaluate on testing set: only for 1_35_AF26\n",
    "    if tuning_type == '1_35_AF26':\n",
    "        Y_test_pred = model.predict(X_test, batch_size=test_batch_size, verbose=1)\n",
    "\n",
    "        # Save results: predictions will be saved in radians; for generation on robot\n",
    "        # Raw and smoothed (low-pass 4Hz)\n",
    "        from postprocessingutils import save_predictions_and_eval\n",
    "        save_predictions_and_eval(save_results_path_prefix + 'MSBMtest_' + tuning_type, \n",
    "                         X_test, Y_test, Y_test_pred, 'MLP_SI', SEGMENT_LEN, test_VIDs, test_VIDs_ind_cnts, \n",
    "                                 N_params=model.count_params())    \n",
    "    \n",
    "    print \"\\tTime taken: \", time.time()-st, (time.time()-st)/60. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#######################################################################################################\n",
    "# Show results on VALIDATION SET\n",
    "# DONE\n",
    "#######################################################################################################\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "import glob\n",
    "from evalutils import show_test_results, plot_predictions\n",
    "\n",
    "tuning_types = [\n",
    "    '1_35_AF13',\n",
    "    '1_35_AF26', \n",
    "    '1_35_AF52', \n",
    "    '1_35_AF78'\n",
    "]\n",
    "\n",
    "model_names = [\n",
    "    'm_1000_0.0141_0.0183.hdf5', \n",
    "    'm_0360_0.0143_0.0184.hdf5',\n",
    "    'm_0903_0.0139_0.0185.hdf5',\n",
    "    'm_0667_0.0140_0.0182.hdf5'\n",
    "]\n",
    "\n",
    "TE_folder = 'TrainingExamples_16kHz'\n",
    "save_results_path_prefix = './../Dataset/'+TE_folder+'/Results/MLP_SI/XXXMSBM'  # best model\n",
    "\n",
    "for tuning_type, model_name in zip(tuning_types, model_names):\n",
    "\n",
    "    print tuning_type\n",
    "    d = np.load(save_results_path_prefix + 'valtest_' + tuning_type + '.npz')\n",
    "    \n",
    "    ###############################################################################\n",
    "    # Show testing results: for raw Y and smoothed Y\n",
    "    #print \"===========================================Raw=====================\\n\"\n",
    "    #show_test_results(d['results_raw'])\n",
    "    print \"===========================================Smooth=====================\\n\"\n",
    "    show_test_results(d['results_smooth'])\n",
    "    print \"================================================================\\n\"\n",
    "\n",
    "    ###############################################################################\n",
    "    # Plot predictions (post-smoothed and raw) against ground truths and audio \n",
    "    t_VID = 1 # test VID to show\n",
    "    if t_VID >= len(d['Y_raw_list']):\n",
    "        raise ValueError(\"Required test VID is out of bounds!\")\n",
    "    Y_true = d['Y_true_list'][t_VID]\n",
    "    Y_raw = d['Y_raw_list'][t_VID]\n",
    "    Y_smooth = d['Y_smooth_list'][t_VID]\n",
    "    test_VID = d['test_VIDs'][t_VID]\n",
    "\n",
    "    plot_predictions(Y_true, Y_raw, Y_smooth, 'MLP_SI', angles_to_show='all', \n",
    "                         plot_start=13.0, plot_length=3.0, input_mode='time', SD_offset=None, \n",
    "                         test_VID=test_VID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#######################################################################################################\n",
    "# Show results on TESTING SET\n",
    "# DONE\n",
    "#######################################################################################################\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "import glob\n",
    "from evalutils import show_test_results, plot_predictions\n",
    "\n",
    "tuning_type = '1_35_AF26'\n",
    "\n",
    "TE_folder = 'TrainingExamples_16kHz'\n",
    "\n",
    "save_results_path_prefix = './../Dataset/'+TE_folder+'/Results/MLP_SI/XXXMSBM'  # best model\n",
    "\n",
    "d = np.load(save_results_path_prefix + 'test_' + tuning_type + '.npz')\n",
    "\n",
    "print tuning_type\n",
    "\n",
    "###############################################################################\n",
    "# Show testing results: for raw Y and smoothed Y\n",
    "#print \"===========================================Raw=====================\\n\"\n",
    "#show_test_results(d['results_raw'])\n",
    "print \"===========================================Smooth=====================\\n\"\n",
    "show_test_results(d['results_smooth'])\n",
    "print \"================================================================\\n\"\n",
    "\n",
    "###############################################################################\n",
    "# Plot predictions (post-smoothed and raw) against ground truths and audio \n",
    "t_VID = 2 # test VID to show\n",
    "if t_VID >= len(d['Y_raw_list']):\n",
    "    raise ValueError(\"Required test VID is out of bounds!\")\n",
    "Y_true = d['Y_true_list'][t_VID]\n",
    "Y_raw = d['Y_raw_list'][t_VID]\n",
    "Y_smooth = d['Y_smooth_list'][t_VID]\n",
    "test_VID = d['test_VIDs'][t_VID]\n",
    "\n",
    "plot_predictions(Y_true, Y_raw, Y_smooth, 'MLP_SI', angles_to_show='all', \n",
    "                     plot_start=10.0, plot_length=3.0, input_mode='time', SD_offset=None, \n",
    "                     test_VID=test_VID)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
