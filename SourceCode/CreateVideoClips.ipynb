{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################################################################\n",
    "# Audio-driven upper-body motion synthesis on a humanoid robot\n",
    "# Computer Science Tripos Part III Project\n",
    "# Jan Ondras (jo356@cam.ac.uk), Trinity College, University of Cambridge\n",
    "# 2017/18\n",
    "#############################################################################################################\n",
    "# Automatically create video clips from the recordings of the robot - for web-surveys.\n",
    "# 1.) Add audio to video\n",
    "# 2.) Create side-by-side videos\n",
    "# and ensure synchronisation betwen audio and videos.\n",
    "# For both NATURAL and SYNTHETIC speech. \n",
    "# Save randomisations of videos in the surveys (i.e. ground truths).\n",
    "#######################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################\n",
    "# Get duration of video/audio\n",
    "import subprocess\n",
    "from datetime import datetime\n",
    "def getDuration(filename):\n",
    "    result = subprocess.Popen([\"ffprobe\", filename],\n",
    "    stdout = subprocess.PIPE, stderr = subprocess.STDOUT)\n",
    "    duration_line = [x for x in result.stdout.readlines() if \"Duration\" in x]\n",
    "    #print duration_line\n",
    "    d = (duration_line[0].split(' ')[3]).split(',')[0]\n",
    "    dt = datetime.strptime(d, \"%H:%M:%S.%f\")\n",
    "    dt0 = datetime.strptime('00:00:00.00', \"%H:%M:%S.%f\")\n",
    "    return (dt-dt0).total_seconds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# For natural speech, need to take only last LAST_N_PRED predictions on the original recordings \n",
    "# because only they correspond to the test partition\n",
    "# => create endings of all .wav files\n",
    "# DONE\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "TE_folder = 'TrainingExamples_16kHz'\n",
    "unique_srt_VIDs = unique_srt_VIDs = np.load('./../Dataset/'+TE_folder+'/te_unique_srt_VIDs.npz')['unique_srt_VIDs'] # sorted VIDs\n",
    "\n",
    "dt = 1./100. # 1/FPS\n",
    "\n",
    "for v, VID in enumerate(unique_srt_VIDs):\n",
    "    SID = VID[:5]\n",
    "    predictions_path = './../Dataset/'+TE_folder+'/Results/MLP_SD/XXXMSBMtest_' + SID + '_1_35_AF26.npz'\n",
    "    dd = np.load(predictions_path)\n",
    "    if v % 2 == 0:\n",
    "        LAST_N_PRED = len( dd['Y_smooth_list'][0] )\n",
    "    else:\n",
    "        LAST_N_PRED = len( dd['Y_smooth_list'][1] )\n",
    "    #print LAST_N_PRED\n",
    "    \n",
    "    IN_AUDIO_PATH = './../Dataset/AudioWav_16kHz/' + VID + '.wav'\n",
    "    OUT_AUDIO_PATH = './../Dataset/AudioWav_16kHz_Endings/' + VID + '.wav'\n",
    "    \n",
    "    print \"Cut length:\", LAST_N_PRED*dt\n",
    "    \n",
    "    org_len = getDuration(IN_AUDIO_PATH)\n",
    "    startCut = org_len-LAST_N_PRED*dt\n",
    "    \n",
    "    cmd = 'ffmpeg -i ' + IN_AUDIO_PATH + ' -ss ' + str(startCut) + ' -c copy ' + OUT_AUDIO_PATH\n",
    "    print cmd\n",
    "    if os.system(cmd) != 0:\n",
    "        raise ValueError('Command failed!')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#######################################################################################################\n",
    "# For NATURAL speech based survey: \n",
    "# (1) sync videos with speech\n",
    "# (2) create SBS videos with speech\n",
    "#######################################################################################################\n",
    "\n",
    "#######################################################################################################\n",
    "# (1) Add audio to robot video and synchronise \n",
    "# DONE\n",
    "#######################################################################################################\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "TE_folder = 'TrainingExamples_16kHz'\n",
    "unique_srt_VIDs = unique_srt_VIDs = np.load('./../Dataset/'+TE_folder+'/te_unique_srt_VIDs.npz')['unique_srt_VIDs'] # sorted VIDs\n",
    "all_srt_VIDs = np.load('./../Dataset/'+TE_folder+'/te_VIDs.npz')['VIDs']\n",
    "unique_srt_SIDs = np.array([x[:5] for i, x in enumerate(unique_srt_VIDs) if i % 2 == 0]) # ['PID02', 'PID05', ..\n",
    "\n",
    "in_path_prefix = '/home/janciovec/Desktop/' # robot videos, without audio\n",
    "\n",
    "model_types = [\n",
    "    'MLP_SD',\n",
    "    'LSTM_SD',\n",
    "    'MLP_SI',\n",
    "    'LSTM_SI'\n",
    "]\n",
    "\n",
    "# Iterate over all subjects\n",
    "for s, SID in enumerate(unique_srt_SIDs):\n",
    "\n",
    "    # Iterate over all videos of the subject\n",
    "    for v, VID in enumerate([SID + 'Task2', SID + 'Task3']):\n",
    "\n",
    "        # Iterate over all 4 models\n",
    "        for model_type in model_types:\n",
    "            recording_name = model_type + \"_\" + VID\n",
    "\n",
    "            print recording_name\n",
    "\n",
    "            IN_VIDEO_PATH = in_path_prefix + 'RR_videos/' + recording_name + '.mp4'\n",
    "            SY_VIDEO_PATH = in_path_prefix + 'SY_videos/SY_' + recording_name + '.mp4'    # sync\n",
    "            AV_VIDEO_PATH = in_path_prefix + 'AV_videos/AV_' + recording_name + '.mp4'    # audio-visual\n",
    "\n",
    "            IN_AUDIO_PATH = './../Dataset/AudioWav_16kHz_Endings/' + VID + '.wav'\n",
    "\n",
    "            # Sync audio and video\n",
    "            SPEEDUP =  getDuration(IN_AUDIO_PATH) / getDuration(IN_VIDEO_PATH)\n",
    "            cmd = 'ffmpeg -i '+IN_VIDEO_PATH+' -filter:v \"setpts='+str(SPEEDUP)+'*PTS\" '+SY_VIDEO_PATH\n",
    "            print cmd\n",
    "            if os.system(cmd) != 0:\n",
    "                raise ValueError('Command failed!')\n",
    "\n",
    "            # Add audio to video\n",
    "            cmd = 'ffmpeg -i ' + SY_VIDEO_PATH + ' -i ' + IN_AUDIO_PATH + ' -vcodec libx264 -acodec libmp3lame ' + AV_VIDEO_PATH\n",
    "            print cmd\n",
    "            if os.system(cmd) != 0:\n",
    "                raise ValueError('Command failed!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# (2)\n",
    "# DONE\n",
    "#######################################################################################################\n",
    "# Create side-by-side video\n",
    "def createSideBySideVideo(VIDEO_FILE_A, VIDEO_FILE_B, SBS_OUTPUT): # input is already synchronised\n",
    "    SBS_MUTE_path_prefix = '/home/janciovec/Desktop/SBS_videos/MUTE/'\n",
    "    SBS_OUTPUT_TMP = SBS_MUTE_path_prefix + SBS_OUTPUT.split('/')[-1][:-4] + '_MUTE.mp4'\n",
    "\n",
    "    cmd = 'ffmpeg -i '+VIDEO_FILE_A+' -i '+VIDEO_FILE_B+' -filter_complex \"[0:v]pad=iw*2:ih[int];[int][1:v]overlay=W/2:0[vid]\" -map [vid] -c:v libx264 ' + SBS_OUTPUT_TMP\n",
    "    print cmd\n",
    "    if os.system(cmd) != 0:\n",
    "        raise ValueError('Command failed!')\n",
    "        \n",
    "    # Add audio to video\n",
    "    VID = SBS_OUTPUT.split('_')[-1][:10]\n",
    "    #print VID\n",
    "    IN_AUDIO_PATH = './../Dataset/AudioWav_16kHz_Endings/' + VID + '.wav'\n",
    "    cmd = 'ffmpeg -i ' + SBS_OUTPUT_TMP + ' -i ' + IN_AUDIO_PATH + ' -vcodec libx264 -acodec libmp3lame ' + SBS_OUTPUT\n",
    "    print cmd\n",
    "    if os.system(cmd) != 0:\n",
    "        raise ValueError('Command failed!')\n",
    "        \n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "TE_folder = 'TrainingExamples_16kHz'\n",
    "unique_srt_VIDs = unique_srt_VIDs = np.load('./../Dataset/'+TE_folder+'/te_unique_srt_VIDs.npz')['unique_srt_VIDs'] # sorted VIDs\n",
    "all_srt_VIDs = np.load('./../Dataset/'+TE_folder+'/te_VIDs.npz')['VIDs']\n",
    "unique_srt_SIDs = np.array([x[:5] for i, x in enumerate(unique_srt_VIDs) if i % 2 == 0]) # ['PID02', 'PID05', ..\n",
    "\n",
    "np.random.seed(37)\n",
    "AV_path_prefix = '/home/janciovec/Desktop/AV_videos/AV_'\n",
    "SBS_path_prefix = '/home/janciovec/Desktop/SBS_videos/SBS_'\n",
    "\n",
    "rand_SI_list = []\n",
    "rand_SD_list = []\n",
    "    \n",
    "for v, VID in enumerate(unique_srt_VIDs):\n",
    "        \n",
    "    ######\n",
    "    # SI\n",
    "    ######\n",
    "    # Randomly choose which model is on left/right side\n",
    "    rand_SI = np.random.randint(0, 2)\n",
    "    rand_SI_list.append( [VID, str(rand_SI)] )\n",
    "    \n",
    "    if rand_SI == 0:                 # MLP on left:      MLP-LSTM\n",
    "        VIDEO_FILE_A = AV_path_prefix + 'MLP_SI_' + VID + '.mp4'\n",
    "        VIDEO_FILE_B = AV_path_prefix + 'LSTM_SI_' + VID + '.mp4'   \n",
    "    else:                            # MLP on right:     LSTM-MLP\n",
    "        VIDEO_FILE_A = AV_path_prefix + 'LSTM_SI_' + VID + '.mp4'\n",
    "        VIDEO_FILE_B = AV_path_prefix + 'MLP_SI_' + VID + '.mp4'\n",
    "        \n",
    "    SBS_OUTPUT = SBS_path_prefix + 'SI_' + VID + '.mp4'\n",
    "    createSideBySideVideo(VIDEO_FILE_A, VIDEO_FILE_B, SBS_OUTPUT)\n",
    "        \n",
    "    ######\n",
    "    # SD\n",
    "    ######\n",
    "    # Randomly choose which model is on left/right side\n",
    "    rand_SD = np.random.randint(0, 2)\n",
    "    rand_SD_list.append( [VID, str(rand_SD)] )\n",
    "    \n",
    "    if rand_SD == 0:                 # MLP on left:      MLP-LSTM\n",
    "        VIDEO_FILE_A = AV_path_prefix + 'MLP_SD_' + VID + '.mp4'\n",
    "        VIDEO_FILE_B = AV_path_prefix + 'LSTM_SD_' + VID + '.mp4'   \n",
    "    else:                            # MLP on right:     LSTM-MLP\n",
    "        VIDEO_FILE_A = AV_path_prefix + 'LSTM_SD_' + VID + '.mp4'\n",
    "        VIDEO_FILE_B = AV_path_prefix + 'MLP_SD_' + VID + '.mp4'\n",
    "        \n",
    "    SBS_OUTPUT = SBS_path_prefix + 'SD_' + VID + '.mp4'\n",
    "    createSideBySideVideo(VIDEO_FILE_A, VIDEO_FILE_B, SBS_OUTPUT)  \n",
    "        \n",
    "        \n",
    "# Save the randomisation\n",
    "        \n",
    "rand_SI_list = np.array(rand_SI_list)\n",
    "np.random.shuffle(rand_SI_list)         # randomise order of videos\n",
    "print rand_SI_list\n",
    "rand_SD_list = np.array(rand_SD_list)\n",
    "np.random.shuffle(rand_SD_list)         # randomise order of videos\n",
    "print rand_SD_list\n",
    "np.savez('./../Dataset/Survey/survey_groundTruths.npz', SI=rand_SI_list, SD=rand_SD_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################################################################\n",
    "# For SYNTHETIC speech based survey: \n",
    "# (1) sync videos with speech\n",
    "# (2) create SBS videos with speech\n",
    "#######################################################################################################\n",
    "\n",
    "# (1)\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "in_path_prefix = '/home/janciovec/Desktop/' # robot videos, without audio\n",
    "\n",
    "TTS_methods = [\n",
    "    'MOB', # MaryTTS, voice obadiah\n",
    "    'MSP', # MaryTTS, voice spike\n",
    "    'MPR', # MaryTTS, voice prudence\n",
    "    'MPO'  # MaryTTS, voice poppy\n",
    "]\n",
    "model_types = ['LSTM_SI', 'MLP_SI']\n",
    "IDs = ['6', '7', '8', '9'] # stories Banana, Picnic, Army, Glasses: http://docs.autismresearchcentre.com/papers/1999_Jolliffe_BC_Stories.pdf\n",
    "\n",
    "# Iterate over 2 models\n",
    "for model_type in model_types:\n",
    "    # Iterate over 4 stories\n",
    "    for ID in IDs:\n",
    "        # Iterate over 4 voices\n",
    "        for TTS_method in TTS_methods:\n",
    "\n",
    "            recording_name = model_type + \"_SYNTHETIC\" + ID + TTS_method\n",
    "            print recording_name\n",
    "\n",
    "            IN_VIDEO_PATH = in_path_prefix + 'RR_videos/' + recording_name + '.mp4'\n",
    "            SY_VIDEO_PATH = in_path_prefix + 'SY_videos/SY_' + recording_name + '.mp4'    # sync\n",
    "            AV_VIDEO_PATH = in_path_prefix + 'AV_videos/AV_' + recording_name + '.mp4'    # audio-visual\n",
    "\n",
    "            IN_AUDIO_PATH = './../Dataset/Synthetic_TTS/SYNTHETIC_audio_' + ID + '_' + TTS_method + '.wav'\n",
    "\n",
    "            # Sync audio and video\n",
    "            SPEEDUP =  getDuration(IN_AUDIO_PATH) / getDuration(IN_VIDEO_PATH)\n",
    "            cmd = 'ffmpeg -i '+IN_VIDEO_PATH+' -filter:v \"setpts='+str(SPEEDUP)+'*PTS\" '+SY_VIDEO_PATH\n",
    "            print cmd\n",
    "            if os.system(cmd) != 0:\n",
    "                raise ValueError('Command failed!')\n",
    "\n",
    "            # Add audio to video\n",
    "            cmd = 'ffmpeg -i ' + SY_VIDEO_PATH + ' -i ' + IN_AUDIO_PATH + ' -vcodec libx264 -acodec libmp3lame ' + AV_VIDEO_PATH\n",
    "            print cmd\n",
    "            if os.system(cmd) != 0:\n",
    "                raise ValueError('Command failed!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# (2)\n",
    "\n",
    "#######################################################################################################\n",
    "# Create side-by-side video\n",
    "def createSideBySideVideo(VIDEO_FILE_A, VIDEO_FILE_B, SBS_OUTPUT, ID, TTS_method): # input is already synchronised\n",
    "        \n",
    "    SBS_MUTE_path_prefix = '/home/janciovec/Desktop/SBS_videos/MUTE/'\n",
    "    SBS_OUTPUT_TMP = SBS_MUTE_path_prefix + SBS_OUTPUT.split('/')[-1][:-4] + '_MUTE.mp4'\n",
    "    cmd = 'ffmpeg -i '+VIDEO_FILE_A+' -i '+VIDEO_FILE_B+' -filter_complex \"[0:v]pad=iw*2:ih[int];[int][1:v]overlay=W/2:0[vid]\" -map [vid] -c:v libx264 ' + SBS_OUTPUT_TMP\n",
    "    print cmd\n",
    "    if os.system(cmd) != 0:\n",
    "        raise ValueError('Command failed!')\n",
    "        \n",
    "    # Add audio to video\n",
    "    IN_AUDIO_PATH = './../Dataset/Synthetic_TTS/SYNTHETIC_audio_' + ID + '_' + TTS_method + '.wav'\n",
    "    cmd = 'ffmpeg -i ' + SBS_OUTPUT_TMP + ' -i ' + IN_AUDIO_PATH + ' -vcodec libx264 -acodec libmp3lame ' + SBS_OUTPUT\n",
    "    print cmd\n",
    "    if os.system(cmd) != 0:\n",
    "        raise ValueError('Command failed!')\n",
    "        \n",
    "np.random.seed(37)\n",
    "\n",
    "AV_path_prefix = '/home/janciovec/Desktop/AV_videos/AV_'\n",
    "SBS_path_prefix = '/home/janciovec/Desktop/SBS_videos/SBS_'\n",
    "\n",
    "# EachRandomly choose where \n",
    "\n",
    "TTS_methods = [\n",
    "    'MOB', # MaryTTS, voice obadiah\n",
    "    'MSP', # MaryTTS, voice spike\n",
    "    'MPR', # MaryTTS, voice prudence\n",
    "    'MPO'  # MaryTTS, voice poppy\n",
    "]\n",
    "model_types = ['LSTM_SI', 'MLP_SI']\n",
    "IDs = ['6', '7', '8', '9'] # stories Banana, Picnic, Army, Glasses: http://docs.autismresearchcentre.com/papers/1999_Jolliffe_BC_Stories.pdf\n",
    "\n",
    "rand_list = []    # triples <story ID, character ID, position of models (0=>MLPfirst)>\n",
    "\n",
    "# Iterate over 4 stories\n",
    "for ID in IDs:\n",
    "    # Iterate over 4 voices\n",
    "    for TTS_method in TTS_methods:\n",
    "\n",
    "        ######\n",
    "        # SI\n",
    "        ######\n",
    "        # Randomly choose which model is on left/right side\n",
    "        rand_i = np.random.randint(0, 2)\n",
    "        rand_list.append( [ID, TTS_method, str(rand_i)] )\n",
    "\n",
    "        VID = 'SYNTHETIC' + ID + TTS_method\n",
    "\n",
    "        if rand_i == 0:                 # MLP on left:      MLP-LSTM\n",
    "            VIDEO_FILE_A = AV_path_prefix + 'MLP_SI_' + VID + '.mp4'\n",
    "            VIDEO_FILE_B = AV_path_prefix + 'LSTM_SI_' + VID + '.mp4'   \n",
    "        else:                            # MLP on right:     LSTM-MLP\n",
    "            VIDEO_FILE_A = AV_path_prefix + 'LSTM_SI_' + VID + '.mp4'\n",
    "            VIDEO_FILE_B = AV_path_prefix + 'MLP_SI_' + VID + '.mp4'\n",
    "\n",
    "        SBS_OUTPUT = SBS_path_prefix + VID + '.mp4'\n",
    "        createSideBySideVideo(VIDEO_FILE_A, VIDEO_FILE_B, SBS_OUTPUT, ID, TTS_method)\n",
    "        \n",
    "##########################################################################\n",
    "# Save the randomisation (which side & overall ordering of all 16 clips)\n",
    "rand_list = np.array(rand_list)\n",
    "print rand_list\n",
    "np.random.shuffle(rand_list)         # randomise order of videos\n",
    "print rand_list\n",
    "np.savez('./../Dataset/Survey/survey_synthSpeech_groundTruths.npz', gt=rand_list)\n",
    "print \"Saved to:\"\n",
    "print './../Dataset/Survey/survey_synthSpeech_groundTruths.npz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
