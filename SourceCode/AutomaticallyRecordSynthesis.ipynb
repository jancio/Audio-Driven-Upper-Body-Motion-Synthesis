{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################################################################\n",
    "# Audio-driven upper-body motion synthesis on a humanoid robot\n",
    "# Computer Science Tripos Part III Project\n",
    "# Jan Ondras (jo356@cam.ac.uk), Trinity College, University of Cambridge\n",
    "# 2017/18\n",
    "#############################################################################################################\n",
    "# Automatically record synthesis on virtual robot. \n",
    "# Requires the program SimpleScreenRecorder and the pyautogui library. \n",
    "#############################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################################################################\n",
    "# OFFLINE case: predictions are precomputed (loaded from file)\n",
    "# (A) from the original test set\n",
    "# (B) from TTS system (synthetic speech)\n",
    "#######################################################################################################\n",
    "# BEFORE STARTING RUN: \n",
    "# export PYTHONPATH=${PYTHONPATH}:~/Desktop/pynaoqi-python2.7-2.5.5.5-linux64/lib/python2.7/site-packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################################################################\n",
    "# (A) Predictions made on NATURAL SPEECH from original test set\n",
    "#######################################################################################################\n",
    "\n",
    "import pyautogui\n",
    "from naoqi import ALProxy\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "PA_pause = 0.2 # pyautogui.PAUSE not after starting the recorder\n",
    "\n",
    "TE_folder = 'TrainingExamples_16kHz'\n",
    "unique_srt_VIDs = unique_srt_VIDs = np.load('./../Dataset/'+TE_folder+'/te_unique_srt_VIDs.npz')['unique_srt_VIDs'] # sorted VIDs\n",
    "all_srt_VIDs = np.load('./../Dataset/'+TE_folder+'/te_VIDs.npz')['VIDs']\n",
    "unique_srt_SIDs = np.array([x[:5] for i, x in enumerate(unique_srt_VIDs) if i % 2 == 0]) # ['PID02', 'PID05', ..\n",
    "\n",
    "model_types = [\n",
    "    'MLP_SD',\n",
    "    'LSTM_SD',\n",
    "    'MLP_SI',\n",
    "    'LSTM_SI'\n",
    "]\n",
    "\n",
    "FR = 100. # frame rate of pose features\n",
    "dt = 1./FR\n",
    "angles_names = [\n",
    "    \"HeadPitch\", \"HeadYaw\", \n",
    "    \"LShoulderRoll\", \"LShoulderPitch\", \"LElbowRoll\", \"LElbowYaw\",\n",
    "    \"RShoulderRoll\", \"RShoulderPitch\", \"RElbowRoll\", \"RElbowYaw\", \n",
    "    \"HipRoll\"\n",
    "]\n",
    "N_targets = 11\n",
    "angles_used_i = np.arange(N_targets)\n",
    "\n",
    "# Connect to the robot\n",
    "IP = \"127.0.0.1\"\n",
    "port = 38613\n",
    "motionProxy = ALProxy(\"ALMotion\", IP, port)\n",
    "# print \"Simulating on virtual robot ... (pose features extracted using LFTD)\"\n",
    "\n",
    "\n",
    "# Iterate over all subjects\n",
    "for s, SID in enumerate(unique_srt_SIDs):\n",
    "\n",
    "    # Iterate over all videos of the subject\n",
    "    for v, VID in enumerate([SID + 'Task2', SID + 'Task3']):\n",
    "\n",
    "        # Iterate over all 4 models\n",
    "        for model_type in model_types:\n",
    "            recording_name = model_type + \"_\" + VID\n",
    "            print recording_name\n",
    "                       \n",
    "            # Load predictions\n",
    "            if model_type == 'MLP_SI' or model_type == 'LSTM_SI': \n",
    "                predictions_path = './../Dataset/'+TE_folder+'/Results/' + model_type + '/cvTest/test_' + SID + '.npz'\n",
    "            elif model_type == 'MLP_SD':\n",
    "                predictions_path = './../Dataset/'+TE_folder+'/Results/' + model_type + '/XXXMSBMtest_' + SID + '_1_35_AF26.npz'\n",
    "            elif model_type == 'LSTM_SD':\n",
    "                predictions_path = './../Dataset/'+TE_folder+'/Results/' + model_type + '/MSBMtest_1_26_12_' + SID + '.npz'\n",
    "            else:\n",
    "                raise ValueError(\"Unknown model type!\")\n",
    "            dd = np.load(predictions_path)\n",
    "            if dd['test_VIDs'][v] != VID:\n",
    "                raise ValueError('Check VIDs!')\n",
    "            Y_pred = dd['Y_smooth_list'][v]\n",
    "            # Save the number of frames predicted by SD models; to be used to offset from the end of predictions by SI models\n",
    "            if model_type == 'MLP_SD':\n",
    "                LAST_N_PRED = len(Y_pred)\n",
    "            # Keep last LAST_N_PRED predictions\n",
    "            Y_pred = Y_pred[-LAST_N_PRED:]\n",
    "            print len(Y_pred)\n",
    "            \n",
    "            # Reset robot to neutral pose\n",
    "            for an in angles_names:\n",
    "                angle_reset = 0.\n",
    "                if an == 'LShoulderPitch' or an == 'RShoulderPitch':\n",
    "                    angle_reset = angle_reset + np.pi/2\n",
    "                motionProxy.setAngles(an, angle_reset, 1.)\n",
    "            \n",
    "            # Set recording name & press continue\n",
    "            pyautogui.click(x=1128, y=168, pause=PA_pause)\n",
    "            pyautogui.hotkey('ctrl', 'a', pause=PA_pause)\n",
    "            pyautogui.press('delete', pause=PA_pause)\n",
    "            pyautogui.typewrite('/home/janciovec/Desktop/RR_videos/' + recording_name + '.mp4', interval=0.05) # enter recording name\n",
    "            pyautogui.click(x=1087, y=656, pause=PA_pause) # click continue\n",
    "            \n",
    "            # START RECORDING\n",
    "            pyautogui.click(x=998, y=99)  # start\n",
    "            \n",
    "            # START SIMULATION\n",
    "            # Simulate/synthesis\n",
    "            st = time.time()\n",
    "            for frame_i, angles_vector in enumerate(Y_pred):\n",
    "                for angle_i in angles_used_i:\n",
    "                    motionProxy.setAngles(angles_names[angle_i], angles_vector[angle_i], 1.)\n",
    "                adaptive_dt = ((frame_i+1.) * dt - time.time() + st)\n",
    "                #print adaptive_dt\n",
    "                if adaptive_dt > 0.:\n",
    "                    time.sleep(0.95*adaptive_dt)\n",
    "            \n",
    "            # STOP RECORDING & click \"Save recording\" & prepare for next one\n",
    "            pyautogui.click(x=998, y=99, pause=PA_pause)   # stop\n",
    "            pyautogui.click(x=1087, y=656, pause=PA_pause) # save\n",
    "            pyautogui.click(x=1087, y=656, pause=PA_pause) # back to start\n",
    "            pyautogui.click(x=1087, y=656, pause=PA_pause) # click continue\n",
    "            pyautogui.click(x=1087, y=656, pause=PA_pause) # click continue\n",
    "            \n",
    "            et = time.time()\n",
    "            print \"\\tTotal simulation time: \", et - st, \" s = \", (et - st)/60., \" min\"\n",
    "            print \"===================================================================================\\n\"\n",
    "            time.sleep(3.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################################################################\n",
    "# (B) Predictions made on SYNTHETIC SPEECH\n",
    "#######################################################################################################\n",
    "\n",
    "import pyautogui\n",
    "from naoqi import ALProxy\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "PA_pause = 0.2 # pyautogui.PAUSE, not after starting the recorder\n",
    "\n",
    "TE_folder = 'TrainingExamples_16kHz'\n",
    "\n",
    "FR = 100. # frame rate of pose features\n",
    "dt = 1./FR\n",
    "angles_names = [\n",
    "    \"HeadPitch\", \"HeadYaw\", \n",
    "    \"LShoulderRoll\", \"LShoulderPitch\", \"LElbowRoll\", \"LElbowYaw\",\n",
    "    \"RShoulderRoll\", \"RShoulderPitch\", \"RElbowRoll\", \"RElbowYaw\", \n",
    "    \"HipRoll\"\n",
    "]\n",
    "N_targets = 11\n",
    "angles_used_i = np.arange(N_targets)\n",
    "\n",
    "# Connect to the robot\n",
    "IP = \"127.0.0.1\"\n",
    "port = 45699\n",
    "motionProxy = ALProxy(\"ALMotion\", IP, port)\n",
    "# print \"Simulating on virtual robot ... (pose features extracted using LFTD)\"\n",
    "\n",
    "TTS_methods = [\n",
    "    'MOB', # MaryTTS, voice obadiah\n",
    "    'MSP', # MaryTTS, voice spike\n",
    "    'MPR', # MaryTTS, voice prudence\n",
    "    'MPO'  # MaryTTS, voice poppy\n",
    "]\n",
    "\n",
    "save_results_path_prefix = './../Dataset/Synthetic_TTS/'\n",
    "\n",
    "model_types = ['LSTM_SI', 'MLP_SI']\n",
    "\n",
    "IDs = ['6', '7', '8', '9'] # stories Banana, Picnic, Army, Glasses: http://docs.autismresearchcentre.com/papers/1999_Jolliffe_BC_Stories.pdf\n",
    "\n",
    "# Iterate over 2 models\n",
    "for model_type in model_types:\n",
    "    # Iterate over 4 stories\n",
    "    for ID in IDs:\n",
    "        # Iterate over 4 voices\n",
    "        for TTS_method in TTS_methods:\n",
    "\n",
    "            recording_name = model_type + \"_SYNTHETIC\" + ID + TTS_method\n",
    "            print recording_name\n",
    "\n",
    "            # Load predictions\n",
    "            dd = np.load(save_results_path_prefix + 'SYNTHETIC_pred_' + model_type + '_' + ID + '_' + TTS_method + '.npz')\n",
    "            Y_pred = dd['Y_smooth']\n",
    "\n",
    "            # Reset robot to neutral pose\n",
    "            for an in angles_names:\n",
    "                angle_reset = 0.\n",
    "                if an == 'LShoulderPitch' or an == 'RShoulderPitch':\n",
    "                    angle_reset = angle_reset + np.pi/2\n",
    "                motionProxy.setAngles(an, angle_reset, 1.)\n",
    "\n",
    "            # Set recording name & press continue\n",
    "            pyautogui.click(x=1128, y=168, pause=PA_pause)\n",
    "            pyautogui.hotkey('ctrl', 'a', pause=PA_pause)\n",
    "            pyautogui.press('delete', pause=PA_pause)\n",
    "            pyautogui.typewrite('/home/janciovec/Desktop/RR_videos/' + recording_name + '.mp4', interval=0.05) # enter recording name\n",
    "            pyautogui.click(x=1087, y=656, pause=PA_pause) # click continue\n",
    "\n",
    "            # START RECORDING\n",
    "            pyautogui.click(x=998, y=99)  # start\n",
    "\n",
    "            # START SIMULATION\n",
    "            # Simulate/synthesis\n",
    "            st = time.time()\n",
    "            for frame_i, angles_vector in enumerate(Y_pred):\n",
    "                for angle_i in angles_used_i:\n",
    "                    motionProxy.setAngles(angles_names[angle_i], angles_vector[angle_i], 1.)\n",
    "                #time.sleep(dt) # delay by 1/FPS\n",
    "                adaptive_dt = ((frame_i+1.) * dt - time.time() + st)\n",
    "                #print adaptive_dt\n",
    "                if adaptive_dt > 0.:\n",
    "                    time.sleep(0.95*adaptive_dt)\n",
    "\n",
    "            # STOP RECORDING & click \"Save recording\" & prepare for next one\n",
    "            pyautogui.click(x=998, y=99, pause=PA_pause)   # stop\n",
    "            pyautogui.click(x=1087, y=656, pause=PA_pause) # save\n",
    "            pyautogui.click(x=1087, y=656, pause=PA_pause) # back to start\n",
    "            pyautogui.click(x=1087, y=656, pause=PA_pause) # click continue\n",
    "            pyautogui.click(x=1087, y=656, pause=PA_pause) # click continue\n",
    "\n",
    "            et = time.time()\n",
    "            print \"\\tTotal simulation time: \", et - st, \" s = \", (et - st)/60., \" min\"\n",
    "            print \"===================================================================================\\n\"\n",
    "            time.sleep(3.)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
