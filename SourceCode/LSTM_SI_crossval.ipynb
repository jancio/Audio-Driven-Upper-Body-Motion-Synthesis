{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################################################\n",
    "# Audio-driven upper-body motion synthesis on a humanoid robot\n",
    "# Computer Science Tripos Part III Project\n",
    "# Jan Ondras (jo356@cam.ac.uk), Trinity College, University of Cambridge\n",
    "# 2017/18\n",
    "#####################################################################################\n",
    "# 10-fold subject-independent cross-validation of the LSTM-SI model\n",
    "#####################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "###############################################################################################################\n",
    "# Using the LSTM-SI model, train&test on 10 folds (every time 2 test subjects and 2 validation subjects) \n",
    "# Then save the results by subjects\n",
    "###############################################################################################################\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "import glob\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, LSTM, Masking, TimeDistributed\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "from geoutils import radToDeg, degToRad\n",
    "from evalutils import norm_Y, inv_norm_Y\n",
    "from postprocessingutils import save_predictions_and_eval2\n",
    "\n",
    "N_folds = 10\n",
    "\n",
    "SEGMENT_LEN = 300 # for evaluation (local cca)\n",
    "AF_type = 'AF_logFB26_norm'\n",
    "SEG_folder = 'Segments_logFB26'\n",
    "\n",
    "np.random.seed(37) # for reproducibility\n",
    "TE_folder = 'TrainingExamples_16kHz'\n",
    "unique_srt_VIDs = unique_srt_VIDs = np.load('./../Dataset/'+TE_folder+'/te_unique_srt_VIDs.npz')['unique_srt_VIDs'] # sorted VIDs\n",
    "all_srt_VIDs = np.load('./../Dataset/'+TE_folder+'/te_VIDs.npz')['VIDs']\n",
    "unique_srt_SIDs = np.array([x[:5] for i, x in enumerate(unique_srt_VIDs) if i % 2 == 0]) # ['PID02', 'PID05', ..\n",
    "\n",
    "###\n",
    "save_results_path_prefix = './../Dataset/'+TE_folder+'/Results/LSTM_SI/cvTest/'\n",
    "model_checkpoint_path_prefix = './ModelCheckpoints/LSTM_SI/cvTest/'\n",
    "\n",
    "PF = np.load('./../Dataset/'+TE_folder+'/te_PF_smooth_LPBF_4.0.npz')['PF_smooth_LPBF']\n",
    "PF = PF[:, :11]\n",
    "N_targets = PF.shape[1]\n",
    "###########\n",
    "# Target (Y) normalisation, into range 0-1 according to constraints\n",
    "PF = norm_Y(PF)\n",
    "print \"Targets (Y) are TRANSFORMED to 0-1 range\"\n",
    "\n",
    "AF = np.load('./../Dataset/'+TE_folder+'/te_'+AF_type+'.npz')[AF_type]\n",
    "N_features = AF.shape[1]\n",
    "\n",
    "# Learning settings\n",
    "N_epochs = 100\n",
    "dropout = 0.\n",
    "train_batch_size = 15000\n",
    "N_LSTM_units = 12 # BEST FOUND in LSTM_SI\n",
    "\n",
    "########################################################################\n",
    "# For given subject SID (PID02) get corresponding VIDs\n",
    "def get_subjects_VIDs(SIDs):\n",
    "    result_VIDs = []\n",
    "    for SID in SIDs:\n",
    "        # Take VIDs from both tasks, for this subject\n",
    "        result_VIDs.append(  SID + 'Task2' )\n",
    "        result_VIDs.append(  SID + 'Task3' )\n",
    "    return result_VIDs\n",
    "\n",
    "# For given subjects get corresponding indicies into the feature set & also their counts (per VID)\n",
    "def get_subjects_indicies(SIDs):\n",
    "    indicies = []\n",
    "    indicies_cnts = []\n",
    "    for SID in SIDs:\n",
    "        # Take indicies corresponding to both tasks, for this subject\n",
    "        a = np.argwhere(all_srt_VIDs == SID + 'Task2')[:,0]\n",
    "        b = np.argwhere(all_srt_VIDs == SID + 'Task3')[:,0]\n",
    "        indicies.extend( a )\n",
    "        indicies.extend( b )\n",
    "        indicies_cnts.append( len(a) )\n",
    "        indicies_cnts.append( len(b) )\n",
    "    return indicies, indicies_cnts\n",
    "# print frameCnts[26] + frameCnts[27] + frameCnts[0] + frameCnts[1] # checks\n",
    "# print len(get_subjects_indicies(['PID20', 'PID02']))\n",
    "########################################################################\n",
    "\n",
    "#######################################################\n",
    "# Dataset split\n",
    "\n",
    "N_test_SIDs = 2\n",
    "N_val_SIDs = 2\n",
    "N_SIDs = 19\n",
    "N_train_SIDs = N_SIDs - N_test_SIDs - N_val_SIDs\n",
    "print \"Dataset split in terms of subjects (train/val/test): \", 100.*N_train_SIDs/N_SIDs, \"/\", 100.*N_val_SIDs/N_SIDs, \"/\", 100.*N_test_SIDs/N_SIDs, \"%\"\n",
    "print \n",
    "\n",
    "# Randomise the dataset split\n",
    "permI = np.random.permutation(N_SIDs)\n",
    "\n",
    "for fold_i in range(N_folds):\n",
    "    \n",
    "    print permI\n",
    "    train_SIDs_mask = permI[:N_train_SIDs] \n",
    "    val_SIDs_mask =   permI[N_train_SIDs:N_train_SIDs+N_val_SIDs]\n",
    "    test_SIDs_mask =  permI[N_train_SIDs+N_val_SIDs:] \n",
    "    \n",
    "    print \"Train SIDs\",      unique_srt_SIDs[train_SIDs_mask]\n",
    "    print \"Valid SIDs\",      unique_srt_SIDs[val_SIDs_mask]\n",
    "    print \"Testi SIDs\",      unique_srt_SIDs[test_SIDs_mask]\n",
    "\n",
    "    print \"Train SIDs mask\", train_SIDs_mask\n",
    "    print \"Valid SIDs mask\", val_SIDs_mask\n",
    "    print \"Testi SIDs mask\", test_SIDs_mask\n",
    "\n",
    "    train_VIDs = get_subjects_VIDs(unique_srt_SIDs[train_SIDs_mask])\n",
    "    val_VIDs   = get_subjects_VIDs(unique_srt_SIDs[val_SIDs_mask])\n",
    "    test_VIDs  = get_subjects_VIDs(unique_srt_SIDs[test_SIDs_mask])\n",
    "\n",
    "    print \"Train VIDs\", train_VIDs\n",
    "    print \"Valid VIDs\", val_VIDs\n",
    "    print \"Testi VIDs\", test_VIDs\n",
    "\n",
    "    train_mask, train_VIDs_ind_cnts = get_subjects_indicies(unique_srt_SIDs[train_SIDs_mask])\n",
    "    val_mask, val_VIDs_ind_cnts     = get_subjects_indicies(unique_srt_SIDs[val_SIDs_mask])\n",
    "    test_mask, test_VIDs_ind_cnts   = get_subjects_indicies(unique_srt_SIDs[test_SIDs_mask])\n",
    "    # print test_VIDs_ind_cnts\n",
    "\n",
    "    print \"Train/val/test set sizes: \", len(train_mask), \"/\", len(val_mask), \"/\", len(test_mask), \" = \", len(train_mask) + len(val_mask) + len(test_mask)\n",
    "    print \"Dataset split in terms of #examples (train/val/test): \", 100.*len(train_mask)/len(all_srt_VIDs), \"/\", 100.*len(val_mask)/len(all_srt_VIDs), \"/\", 100.*len(test_mask)/len(all_srt_VIDs), \"%\"\n",
    "    print \n",
    "\n",
    "    permI = np.roll(permI, 2) # ROTATE INDICES - FOR NEXT DATASET SPLIT\n",
    "    \n",
    "    Y_train = PF[train_mask]\n",
    "    Y_val   = PF[val_mask]\n",
    "    Y_test  = PF[test_mask]\n",
    "    X_train = AF[train_mask]\n",
    "    X_val   = AF[val_mask]\n",
    "    X_test  = AF[test_mask]  \n",
    "    \n",
    "    train_VIDs_ind_cnts = np.array( train_VIDs_ind_cnts )\n",
    "    val_VIDs_ind_cnts = np.array( val_VIDs_ind_cnts )\n",
    "    test_VIDs_ind_cnts = np.array( test_VIDs_ind_cnts )\n",
    "    \n",
    "    ################################\n",
    "    # Segment training sequences\n",
    "    offset_f = 0 # frames\n",
    "    offset_s = 0 # segments\n",
    "\n",
    "    N_train_seg = train_VIDs_ind_cnts - SEGMENT_LEN + 1 # Array of number of segments per training VID; No padding\n",
    "\n",
    "    X = np.zeros((np.sum(N_train_seg), SEGMENT_LEN, N_features))\n",
    "    Y = np.zeros((np.sum(N_train_seg), SEGMENT_LEN, N_targets))\n",
    "\n",
    "    for i, N_VID_frames in enumerate(train_VIDs_ind_cnts):\n",
    "\n",
    "        for j in range(N_train_seg[i]):\n",
    "\n",
    "            X[offset_s+j] = X_train[offset_f+j:offset_f+j+SEGMENT_LEN]\n",
    "            Y[offset_s+j] = Y_train[offset_f+j:offset_f+j+SEGMENT_LEN]\n",
    "\n",
    "        offset_f += N_VID_frames\n",
    "        offset_s += N_train_seg[i]\n",
    "\n",
    "    X_train = X\n",
    "    Y_train = Y\n",
    "    \n",
    "    ################################\n",
    "    # Segment validation sequences\n",
    "    offset_f = 0 # frames\n",
    "    offset_s = 0 # segments\n",
    "\n",
    "    N_val_seg = val_VIDs_ind_cnts - SEGMENT_LEN + 1 # Array of number of segments per training VID; No padding\n",
    "\n",
    "    X = np.zeros((np.sum(N_val_seg), SEGMENT_LEN, N_features))\n",
    "    Y = np.zeros((np.sum(N_val_seg), SEGMENT_LEN, N_targets))\n",
    "\n",
    "    for i, N_VID_frames in enumerate(val_VIDs_ind_cnts):\n",
    "\n",
    "        for j in range(N_val_seg[i]):\n",
    "\n",
    "            X[offset_s+j] = X_val[offset_f+j:offset_f+j+SEGMENT_LEN]\n",
    "            Y[offset_s+j] = Y_val[offset_f+j:offset_f+j+SEGMENT_LEN]\n",
    "\n",
    "        offset_f += N_VID_frames\n",
    "        offset_s += N_val_seg[i]\n",
    "\n",
    "    X_val = X\n",
    "    Y_val = Y\n",
    "\n",
    "    ################################\n",
    "    # Segment testing sequences (for realtime testing: zero-pad segments at the beginning: #segments=#frames)\n",
    "    offset = 0\n",
    "\n",
    "    X = np.zeros((np.sum(test_VIDs_ind_cnts), SEGMENT_LEN, N_features)) # #segments=#frames\n",
    "    Y = np.zeros((np.sum(test_VIDs_ind_cnts), SEGMENT_LEN, N_targets))\n",
    "\n",
    "    for i, N_VID_frames in enumerate(test_VIDs_ind_cnts):\n",
    "\n",
    "        for j in range(N_VID_frames):\n",
    "            # Do zero-padding at the beginning\n",
    "            if j < SEGMENT_LEN - 1:\n",
    "                X[offset+j, SEGMENT_LEN - j - 1:] = X_test[offset:offset+j+1]\n",
    "                Y[offset+j, SEGMENT_LEN - j - 1:] = Y_test[offset:offset+j+1]\n",
    "            # Otherwise: as in the above section\n",
    "            else:\n",
    "                X[offset+j] = X_test[offset+j-SEGMENT_LEN+1:offset+j+1]\n",
    "                Y[offset+j] = Y_test[offset+j-SEGMENT_LEN+1:offset+j+1]\n",
    "\n",
    "        offset += N_VID_frames\n",
    "        \n",
    "    X_test_RT = X\n",
    "    Y_test_RT = Y    \n",
    "    \n",
    "    #######################################################\n",
    "    # Training\n",
    "        \n",
    "    st = time.time()\n",
    "\n",
    "    ##########################\n",
    "    # Final train & test\n",
    "    \n",
    "    # Create LSTM model\n",
    "    model = Sequential()\n",
    "    model.add( Masking(mask_value=0., input_shape=(SEGMENT_LEN, N_features)) )\n",
    "    model.add( LSTM(N_LSTM_units, return_sequences=True) )  \n",
    "    model.add( TimeDistributed(Dense(N_targets, activation='sigmoid')) )\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    #print model.summary()\n",
    "\n",
    "    # Set early stopping\n",
    "    early_stop = EarlyStopping(monitor='val_loss', patience=10, verbose=1)\n",
    "\n",
    "    # Checkpoint model weights and the model itself: at each epoch\n",
    "    model_checkpoint_name = 'm_{:02d}'.format(i) + '_{epoch:04d}_{loss:.4f}_{val_loss:.4f}.hdf5'\n",
    "    model_checkpoint = ModelCheckpoint(model_checkpoint_path_prefix + model_checkpoint_name, monitor='val_loss', verbose=0, \n",
    "                                       save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "\n",
    "    # Tain & validate\n",
    "    hist = model.fit(X_train, Y_train, validation_data=(X_val, Y_val), epochs=N_epochs, shuffle=True,  \n",
    "                     batch_size=train_batch_size, verbose=0, \n",
    "                     callbacks=[early_stop, model_checkpoint])\n",
    "\n",
    "    #######################################################\n",
    "    # Testing & evaluation & saving results\n",
    "    \n",
    "    test_batch_size = X_test_RT.shape[0]\n",
    "    Y_test_pred = model.predict(X_test_RT, batch_size=test_batch_size, verbose=1)\n",
    "    Y_test_pred = Y_test_pred[:, -1, :] # last item from each segment is the (ONLINE) final prediction\n",
    "    Y_test_true = Y_test_RT[:, -1, :]\n",
    "    X_test_RT_last = X_test_RT[:, -1, :]\n",
    "    #print X_test_RT.shape, X_test_RT_last.shape, Y_test_pred.shape, Y_test_true.shape\n",
    "\n",
    "    # 1. test subject\n",
    "    cnt = test_VIDs_ind_cnts[0] + test_VIDs_ind_cnts[1]\n",
    "    \n",
    "    # Avoid evaluation of PID23 twice\n",
    "    if fold_i == N_folds - 1 and test_VIDs[0][:5] == 'PID23':\n",
    "        pass\n",
    "    else:\n",
    "        save_predictions_and_eval2(save_results_path_prefix + 'test_' + test_VIDs[0][:5], \n",
    "                        X_test_RT_last[:cnt], Y_test_true[:cnt], Y_test_pred[:cnt], 'LSTM_SI', SEGMENT_LEN, test_VIDs[:2], \n",
    "                        test_VIDs_ind_cnts[:2], N_params=model.count_params(), N_epochs=len(hist.history['loss']))    \n",
    "\n",
    "    # 2. test subject\n",
    "    save_predictions_and_eval2(save_results_path_prefix + 'test_' + test_VIDs[2][:5], \n",
    "                    X_test_RT_last[cnt:], Y_test_true[cnt:], Y_test_pred[cnt:], 'LSTM_SI', SEGMENT_LEN, test_VIDs[2:], \n",
    "                    test_VIDs_ind_cnts[2:], N_params=model.count_params(), N_epochs=len(hist.history['loss']))    \n",
    "\n",
    "    print \"\\tTime taken: \", time.time()-st, (time.time()-st)/60.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
