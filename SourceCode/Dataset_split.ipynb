{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PID02Task2\n",
      "\tDataset split (train/val/test):  5341 / 1144 / 1144  =  7629 7629\n",
      "\tDataset split (train/val/test):  70.0 / 15.0 / 15.0 %\n",
      "PID02Task3\n",
      "\tDataset split (train/val/test):  4487 / 961 / 961  =  6409 6409\n",
      "\tDataset split (train/val/test):  70.0 / 15.0 / 15.0 %\n",
      "PID05Task2\n",
      "\tDataset split (train/val/test):  5335 / 1142 / 1142  =  7619 7619\n",
      "\tDataset split (train/val/test):  70.0 / 15.0 / 15.0 %\n",
      "PID05Task3\n",
      "\tDataset split (train/val/test):  5479 / 1174 / 1174  =  7827 7827\n",
      "\tDataset split (train/val/test):  70.0 / 15.0 / 15.0 %\n",
      "PID06Task2\n",
      "\tDataset split (train/val/test):  4127 / 883 / 883  =  5893 5893\n",
      "\tDataset split (train/val/test):  70.0 / 15.0 / 15.0 %\n",
      "PID06Task3\n",
      "\tDataset split (train/val/test):  4321 / 925 / 925  =  6171 6171\n",
      "\tDataset split (train/val/test):  70.0 / 15.0 / 15.0 %\n",
      "PID08Task2\n",
      "\tDataset split (train/val/test):  4585 / 982 / 982  =  6549 6549\n",
      "\tDataset split (train/val/test):  70.0 / 15.0 / 15.0 %\n",
      "PID08Task3\n",
      "\tDataset split (train/val/test):  4365 / 935 / 935  =  6235 6235\n",
      "\tDataset split (train/val/test):  70.0 / 15.0 / 15.0 %\n",
      "PID09Task2\n",
      "\tDataset split (train/val/test):  4877 / 1045 / 1045  =  6967 6967\n",
      "\tDataset split (train/val/test):  70.0 / 15.0 / 15.0 %\n",
      "PID09Task3\n",
      "\tDataset split (train/val/test):  4541 / 973 / 973  =  6487 6487\n",
      "\tDataset split (train/val/test):  70.0 / 15.0 / 15.0 %\n",
      "PID10Task2\n",
      "\tDataset split (train/val/test):  3441 / 737 / 737  =  4915 4915\n",
      "\tDataset split (train/val/test):  70.0 / 15.0 / 15.0 %\n",
      "PID10Task3\n",
      "\tDataset split (train/val/test):  3891 / 833 / 833  =  5557 5557\n",
      "\tDataset split (train/val/test):  70.0 / 15.0 / 15.0 %\n",
      "PID11Task2\n",
      "\tDataset split (train/val/test):  3393 / 727 / 727  =  4847 4847\n",
      "\tDataset split (train/val/test):  70.0 / 15.0 / 15.0 %\n",
      "PID11Task3\n",
      "\tDataset split (train/val/test):  4749 / 1017 / 1017  =  6783 6783\n",
      "\tDataset split (train/val/test):  70.0 / 15.0 / 15.0 %\n",
      "PID13Task2\n",
      "\tDataset split (train/val/test):  3475 / 744 / 744  =  4963 4963\n",
      "\tDataset split (train/val/test):  70.0 / 15.0 / 15.0 %\n",
      "PID13Task3\n",
      "\tDataset split (train/val/test):  2083 / 445 / 445  =  2973 2973\n",
      "\tDataset split (train/val/test):  70.0 / 15.0 / 15.0 %\n",
      "PID15Task2\n",
      "\tDataset split (train/val/test):  3281 / 703 / 703  =  4687 4687\n",
      "\tDataset split (train/val/test):  70.0 / 15.0 / 15.0 %\n",
      "PID15Task3\n",
      "\tDataset split (train/val/test):  5385 / 1153 / 1153  =  7691 7691\n",
      "\tDataset split (train/val/test):  70.0 / 15.0 / 15.0 %\n",
      "PID16Task2\n",
      "\tDataset split (train/val/test):  2819 / 604 / 604  =  4027 4027\n",
      "\tDataset split (train/val/test):  70.0 / 15.0 / 15.0 %\n",
      "PID16Task3\n",
      "\tDataset split (train/val/test):  1905 / 408 / 408  =  2721 2721\n",
      "\tDataset split (train/val/test):  70.0 / 15.0 / 15.0 %\n",
      "PID17Task2\n",
      "\tDataset split (train/val/test):  3643 / 780 / 780  =  5203 5203\n",
      "\tDataset split (train/val/test):  70.0 / 15.0 / 15.0 %\n",
      "PID17Task3\n",
      "\tDataset split (train/val/test):  3879 / 830 / 830  =  5539 5539\n",
      "\tDataset split (train/val/test):  70.0 / 15.0 / 15.0 %\n",
      "PID18Task2\n",
      "\tDataset split (train/val/test):  3281 / 703 / 703  =  4687 4687\n",
      "\tDataset split (train/val/test):  70.0 / 15.0 / 15.0 %\n",
      "PID18Task3\n",
      "\tDataset split (train/val/test):  4111 / 880 / 880  =  5871 5871\n",
      "\tDataset split (train/val/test):  70.0 / 15.0 / 15.0 %\n",
      "PID20Task2\n",
      "\tDataset split (train/val/test):  1823 / 390 / 390  =  2603 2603\n",
      "\tDataset split (train/val/test):  70.0 / 15.0 / 15.0 %\n",
      "PID20Task3\n",
      "\tDataset split (train/val/test):  4125 / 883 / 883  =  5891 5891\n",
      "\tDataset split (train/val/test):  70.0 / 15.0 / 15.0 %\n",
      "PID21Task2\n",
      "\tDataset split (train/val/test):  2455 / 525 / 525  =  3505 3505\n",
      "\tDataset split (train/val/test):  70.0 / 15.0 / 15.0 %\n",
      "PID21Task3\n",
      "\tDataset split (train/val/test):  2301 / 493 / 493  =  3287 3287\n",
      "\tDataset split (train/val/test):  70.0 / 15.0 / 15.0 %\n",
      "PID22Task2\n",
      "\tDataset split (train/val/test):  4687 / 1004 / 1004  =  6695 6695\n",
      "\tDataset split (train/val/test):  70.0 / 15.0 / 15.0 %\n",
      "PID22Task3\n",
      "\tDataset split (train/val/test):  5105 / 1093 / 1093  =  7291 7291\n",
      "\tDataset split (train/val/test):  70.0 / 15.0 / 15.0 %\n",
      "PID23Task2\n",
      "\tDataset split (train/val/test):  4061 / 870 / 870  =  5801 5801\n",
      "\tDataset split (train/val/test):  70.0 / 15.0 / 15.0 %\n",
      "PID23Task3\n",
      "\tDataset split (train/val/test):  3523 / 754 / 754  =  5031 5031\n",
      "\tDataset split (train/val/test):  70.0 / 15.0 / 15.0 %\n",
      "PID24Task2\n",
      "\tDataset split (train/val/test):  5015 / 1074 / 1074  =  7163 7163\n",
      "\tDataset split (train/val/test):  70.0 / 15.0 / 15.0 %\n",
      "PID24Task3\n",
      "\tDataset split (train/val/test):  5173 / 1108 / 1108  =  7389 7389\n",
      "\tDataset split (train/val/test):  70.0 / 15.0 / 15.0 %\n",
      "PID25Task2\n",
      "\tDataset split (train/val/test):  5657 / 1212 / 1212  =  8081 8081\n",
      "\tDataset split (train/val/test):  70.0 / 15.0 / 15.0 %\n",
      "PID25Task3\n",
      "\tDataset split (train/val/test):  3529 / 755 / 755  =  5039 5039\n",
      "\tDataset split (train/val/test):  70.0 / 15.0 / 15.0 %\n",
      "PID26Task2\n",
      "\tDataset split (train/val/test):  3053 / 653 / 653  =  4359 4359\n",
      "\tDataset split (train/val/test):  70.0 / 15.0 / 15.0 %\n",
      "PID26Task3\n",
      "\tDataset split (train/val/test):  2573 / 551 / 551  =  3675 3675\n",
      "\tDataset split (train/val/test):  70.0 / 15.0 / 15.0 %\n"
     ]
    }
   ],
   "source": [
    "#####################################################################################\n",
    "# Audio-driven upper-body motion synthesis on a humanoid robot\n",
    "# Computer Science Tripos Part III Project\n",
    "# Jan Ondras (jo356@cam.ac.uk), Trinity College, University of Cambridge\n",
    "# 2017/18\n",
    "#####################################################################################\n",
    "###############################################################################################################\n",
    "# Split dataset into train/val/test partitions (single split)\n",
    "# Save the train/val/test masks\n",
    "# 1.) For each subject's VID separately: for subject-dependent models\n",
    "# 2.) Overall: for subject-independent models; data from one subject are present only in one of the 3 partitions\n",
    "# REDONE after subject 19 eliminated\n",
    "###############################################################################################################\n",
    "##################\n",
    "# 1.) DONE\n",
    "##################\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "import glob\n",
    "\n",
    "######################################################\n",
    "\n",
    "val_frac = 0.15  # ok for SEGMENT_LEN=300, for SEGMENT_LEN=250 can have 0.10\n",
    "test_frac = 0.15\n",
    "\n",
    "TE_folder = 'TrainingExamples_16kHz'\n",
    "\n",
    "######################################################\n",
    "\n",
    "np.random.seed(37) # for reproducibility\n",
    "\n",
    "unique_srt_VIDs = unique_srt_VIDs = np.load('./../Dataset/'+TE_folder+'/te_unique_srt_VIDs.npz')['unique_srt_VIDs'] # sorted VIDs\n",
    "all_srt_VIDs = np.load('./../Dataset/'+TE_folder+'/te_VIDs.npz')['VIDs']\n",
    "unique_srt_SIDs = np.array([x[:5] for i, x in enumerate(unique_srt_VIDs) if i % 2 == 0]) # ['PID02', 'PID05', ..\n",
    "\n",
    "for v, VID in enumerate(unique_srt_VIDs):\n",
    "    \n",
    "    print VID\n",
    "    mask = np.argwhere(all_srt_VIDs == VID)[:,0]\n",
    "\n",
    "    #######################\n",
    "    # Dataset split\n",
    "    N_ex = len(mask)\n",
    "    N_val_ex =   int(N_ex*val_frac)\n",
    "    N_test_ex =  int(N_ex*test_frac)\n",
    "    N_train_ex = N_ex - N_val_ex - N_test_ex\n",
    "\n",
    "    print \"\\tDataset split (train/val/test): \", N_train_ex, \"/\", N_val_ex, \"/\", N_test_ex, \" = \", N_ex, N_train_ex + N_val_ex + N_test_ex\n",
    "    print \"\\tDataset split (train/val/test): \", 100.*(1.-val_frac-test_frac), \"/\", 100.*val_frac, \"/\", 100.*test_frac, \"%\"\n",
    "\n",
    "    train_mask = mask[ : N_train_ex]\n",
    "    val_mask   = mask[N_train_ex : N_train_ex + N_val_ex]\n",
    "    test_mask  = mask[N_train_ex + N_val_ex : ]\n",
    "    \n",
    "    # Save\n",
    "    np.savez('./../Dataset/'+TE_folder+'/Dataset_split/split_masks_' + VID + '.npz', \n",
    "            train_mask=train_mask, val_mask=val_mask, test_mask=test_mask)\n",
    "\n",
    "# for s, SID in enumerate(unique_srt_SIDs):\n",
    "    \n",
    "#     print SID\n",
    "#     mask1 = np.argwhere(all_srt_VIDs == SID + 'Task2')[:,0]\n",
    "#     mask2 = np.argwhere(all_srt_VIDs == SID + 'Task3')[:,0]\n",
    "#     mask = np.concatenate( (mask1, mask2) )\n",
    "#     #print mask.shape, mask1.shape, mask2.shape\n",
    "\n",
    "#     #######################\n",
    "#     # Dataset split\n",
    "#     N_ex = len(mask)\n",
    "#     N_val_ex =   int(N_ex*val_frac)\n",
    "#     N_test_ex =  int(N_ex*test_frac)\n",
    "#     N_train_ex = N_ex - N_val_ex - N_test_ex\n",
    "\n",
    "#     print \"\\tDataset split (train/val/test): \", N_train_ex, \"/\", N_val_ex, \"/\", N_test_ex, \" = \", N_ex, N_train_ex + N_val_ex + N_test_ex\n",
    "#     print \"\\tDataset split (train/val/test): \", 100.*(1.-val_frac-test_frac), \"/\", 100.*val_frac, \"/\", 100.*test_frac, \"%\"\n",
    "\n",
    "#     # Randomise the dataset split\n",
    "#     permI = np.random.permutation(N_ex)\n",
    "\n",
    "#     train_mask = permI[ : N_train_ex]\n",
    "#     val_mask   = permI[N_train_ex : N_train_ex + N_val_ex]\n",
    "#     test_mask  = permI[N_train_ex + N_val_ex : ]\n",
    "    \n",
    "#     # Save\n",
    "#     np.savez('./../Dataset/'+TE_folder+'/Dataset_split/split_masks_' + SID + '.npz', \n",
    "#             train_mask=train_mask, val_mask=val_mask, test_mask=test_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset split in terms of subjects (train/val/test):  78.9473684211 / 10.5263157895 / 10.5263157895 %\n",
      "\n",
      "[ 1  9  2  4 14  8  0  7 13 18  3 10  6  5 16 17 12 11 15]\n",
      "Train SIDs ['PID05' 'PID16' 'PID06' 'PID09' 'PID22' 'PID15' 'PID02' 'PID13' 'PID21'\n",
      " 'PID26' 'PID08' 'PID17' 'PID11' 'PID10' 'PID24']\n",
      "Valid SIDs ['PID25' 'PID20']\n",
      "Testi SIDs ['PID18' 'PID23']\n",
      "Train SIDs mask [ 1  9  2  4 14  8  0  7 13 18  3 10  6  5 16]\n",
      "Valid SIDs mask [17 12]\n",
      "Testi SIDs mask [11 15]\n",
      "Train VIDs ['PID05Task2', 'PID05Task3', 'PID16Task2', 'PID16Task3', 'PID06Task2', 'PID06Task3', 'PID09Task2', 'PID09Task3', 'PID22Task2', 'PID22Task3', 'PID15Task2', 'PID15Task3', 'PID02Task2', 'PID02Task3', 'PID13Task2', 'PID13Task3', 'PID21Task2', 'PID21Task3', 'PID26Task2', 'PID26Task3', 'PID08Task2', 'PID08Task3', 'PID17Task2', 'PID17Task3', 'PID11Task2', 'PID11Task3', 'PID10Task2', 'PID10Task3', 'PID24Task2', 'PID24Task3']\n",
      "Valid VIDs ['PID25Task2', 'PID25Task3', 'PID20Task2', 'PID20Task3']\n",
      "Testi VIDs ['PID18Task2', 'PID18Task3', 'PID23Task2', 'PID23Task3']\n",
      "\n",
      "Train/val/test set sizes:  171056 / 21614 / 21390  =  214060\n",
      "Dataset split in terms of #examples (train/val/test):  79.9103055218 / 10.097169018 / 9.99252546015 %\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##################\n",
    "# 2.) DONE\n",
    "##################\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "import glob\n",
    "\n",
    "######################################################\n",
    "\n",
    "N_test_SIDs = 2\n",
    "N_val_SIDs = 2\n",
    "N_SIDs = 19\n",
    "\n",
    "TE_folder = 'TrainingExamples_16kHz'\n",
    "\n",
    "######################################################\n",
    "\n",
    "np.random.seed(37) # for reproducibility\n",
    "\n",
    "unique_srt_VIDs = unique_srt_VIDs = np.load('./../Dataset/'+TE_folder+'/te_unique_srt_VIDs.npz')['unique_srt_VIDs'] # sorted VIDs\n",
    "all_srt_VIDs = np.load('./../Dataset/'+TE_folder+'/te_VIDs.npz')['VIDs']\n",
    "unique_srt_SIDs = np.array([x[:5] for i, x in enumerate(unique_srt_VIDs) if i % 2 == 0]) # ['PID02', 'PID05', ..\n",
    "\n",
    "########################################################################\n",
    "# For given subject SID (PID02) get corresponding VIDs\n",
    "def get_subjects_VIDs(SIDs):\n",
    "    result_VIDs = []\n",
    "    for SID in SIDs:\n",
    "        # Take VIDs from both tasks, for this subject\n",
    "        result_VIDs.append(  SID + 'Task2' )\n",
    "        result_VIDs.append(  SID + 'Task3' )\n",
    "    return result_VIDs\n",
    "\n",
    "# For given subjects get corresponding indicies into the feature set & also their counts (per VID)\n",
    "def get_subjects_indicies(SIDs):\n",
    "    indicies = []\n",
    "    indicies_cnts = []\n",
    "    for SID in SIDs:\n",
    "        # Take indicies corresponding to both tasks, for this subject\n",
    "        a = np.argwhere(all_srt_VIDs == SID + 'Task2')[:,0]\n",
    "        b = np.argwhere(all_srt_VIDs == SID + 'Task3')[:,0]\n",
    "        indicies.extend( a )\n",
    "        indicies.extend( b )\n",
    "        indicies_cnts.append( len(a) )\n",
    "        indicies_cnts.append( len(b) )\n",
    "    return indicies, indicies_cnts\n",
    "# print frameCnts[26] + frameCnts[27] + frameCnts[0] + frameCnts[1] # checks\n",
    "# print len(get_subjects_indicies(['PID20', 'PID02']))\n",
    "########################################################################\n",
    "\n",
    "N_train_SIDs = N_SIDs - N_test_SIDs - N_val_SIDs\n",
    "print \"Dataset split in terms of subjects (train/val/test): \", 100.*N_train_SIDs/N_SIDs, \"/\", 100.*N_val_SIDs/N_SIDs, \"/\", 100.*N_test_SIDs/N_SIDs, \"%\"\n",
    "print \n",
    "\n",
    "# Randomise the dataset split\n",
    "permI = np.random.permutation(N_SIDs)\n",
    "print permI\n",
    "print \"Train SIDs\",      unique_srt_SIDs[permI[:N_train_SIDs]]\n",
    "print \"Valid SIDs\",      unique_srt_SIDs[permI[N_train_SIDs:N_train_SIDs+N_val_SIDs]]\n",
    "print \"Testi SIDs\",      unique_srt_SIDs[permI[N_train_SIDs+N_val_SIDs:]]\n",
    "\n",
    "train_SIDs_mask = permI[:N_train_SIDs] \n",
    "val_SIDs_mask =   permI[N_train_SIDs:N_train_SIDs+N_val_SIDs]\n",
    "test_SIDs_mask =  permI[N_train_SIDs+N_val_SIDs:]\n",
    "\n",
    "print \"Train SIDs mask\", train_SIDs_mask\n",
    "print \"Valid SIDs mask\", val_SIDs_mask\n",
    "print \"Testi SIDs mask\", test_SIDs_mask\n",
    "\n",
    "train_VIDs = get_subjects_VIDs(unique_srt_SIDs[train_SIDs_mask])\n",
    "val_VIDs   = get_subjects_VIDs(unique_srt_SIDs[val_SIDs_mask])\n",
    "test_VIDs  = get_subjects_VIDs(unique_srt_SIDs[test_SIDs_mask])\n",
    "\n",
    "print \"Train VIDs\", train_VIDs\n",
    "print \"Valid VIDs\", val_VIDs\n",
    "print \"Testi VIDs\", test_VIDs\n",
    "print \n",
    "    \n",
    "train_mask, train_VIDs_ind_cnts = get_subjects_indicies(unique_srt_SIDs[train_SIDs_mask])\n",
    "val_mask, val_VIDs_ind_cnts     = get_subjects_indicies(unique_srt_SIDs[val_SIDs_mask])\n",
    "test_mask, test_VIDs_ind_cnts   = get_subjects_indicies(unique_srt_SIDs[test_SIDs_mask])\n",
    "# print test_VIDs_ind_cnts\n",
    "\n",
    "print \"Train/val/test set sizes: \", len(train_mask), \"/\", len(val_mask), \"/\", len(test_mask), \" = \", len(train_mask) + len(val_mask) + len(test_mask)\n",
    "print \"Dataset split in terms of #examples (train/val/test): \", 100.*len(train_mask)/len(all_srt_VIDs), \"/\", 100.*len(val_mask)/len(all_srt_VIDs), \"/\", 100.*len(test_mask)/len(all_srt_VIDs), \"%\"\n",
    "print \n",
    "\n",
    "# print len(train_mask), len(val_mask), len(test_mask)                         # checks\n",
    "# print len(all_srt_VIDs),  len(train_mask) + len(val_mask) + len(test_mask)\n",
    "\n",
    "# Save\n",
    "np.savez('./../Dataset/'+TE_folder+'/Dataset_split/split_masks_all.npz', \n",
    "        train_mask=train_mask, val_mask=val_mask, test_mask=test_mask, \n",
    "        train_VIDs=train_VIDs, val_VIDs=val_VIDs, test_VIDs=test_VIDs, \n",
    "        train_VIDs_ind_cnts=train_VIDs_ind_cnts, val_VIDs_ind_cnts=val_VIDs_ind_cnts, test_VIDs_ind_cnts=test_VIDs_ind_cnts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
