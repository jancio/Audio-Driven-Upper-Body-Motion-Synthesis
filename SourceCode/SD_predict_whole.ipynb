{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################################################\n",
    "# Audio-driven upper-body motion synthesis on a humanoid robot\n",
    "# Computer Science Tripos Part III Project\n",
    "# Jan Ondras (jo356@cam.ac.uk), Trinity College, University of Cambridge\n",
    "# 2017/18\n",
    "##########################################################################################\n",
    "# Using SD models (MLP, LSTM) predict on the whole subject's video (not just the test set partition)\n",
    "##########################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p27/lib/python2.7/site-packages/matplotlib/__init__.py:1067: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #2\n",
      "  (fname, cnt))\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p27/lib/python2.7/site-packages/matplotlib/__init__.py:1067: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #3\n",
      "  (fname, cnt))\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p27/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting whole video for:  ['PID18Task2' 'PID18Task3' 'PID23Task2' 'PID23Task3']\n",
      "21390\n",
      "(21390, 26)\n",
      "Loading BEST model from: ./ModelCheckpoints/MLP_SD/1_35_AF26/m_PID18_1000_0.0054_0.0051.hdf5\n",
      "4687/4687 [==============================] - 0s 37us/step\n",
      "Loading BEST model from: ./ModelCheckpoints/MLP_SD/1_35_AF26/m_PID18_1000_0.0054_0.0051.hdf5\n",
      "5871/5871 [==============================] - 0s 9us/step\n",
      "Loading BEST model from: ./ModelCheckpoints/MLP_SD/1_35_AF26/m_PID23_1000_0.0015_0.0014.hdf5\n",
      "5801/5801 [==============================] - 0s 13us/step\n",
      "Loading BEST model from: ./ModelCheckpoints/MLP_SD/1_35_AF26/m_PID23_1000_0.0015_0.0014.hdf5\n",
      "5031/5031 [==============================] - 0s 19us/step\n",
      "Saved (raw & smoothed predictions WITHOUT results) to: ./../Dataset/TrainingExamples_16kHz/Results/MLP_SD/WHOLEtest_MLP_SD\n"
     ]
    }
   ],
   "source": [
    "###############################################################################################################\n",
    "# MLP\n",
    "###############################################################################################################\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import load_model\n",
    "from postprocessingutils import save_predictions_no_eval\n",
    "\n",
    "# Load testing VIDs (4)\n",
    "TE_folder = 'TrainingExamples_16kHz'\n",
    "ds = np.load('./../Dataset/'+TE_folder+'/Dataset_split/split_masks_all.npz')\n",
    "test_VIDs  = ds['test_VIDs']\n",
    "test_VIDs_ind_cnts = ds['test_VIDs_ind_cnts']\n",
    "print \"Predicting whole video for: \", test_VIDs\n",
    "print np.sum(test_VIDs_ind_cnts)\n",
    "\n",
    "tuning_type = '1_35_AF26'\n",
    "AF_type = 'AF_logFB26_norm'\n",
    "model_checkpoint_path_prefix = './ModelCheckpoints/MLP_SD/'\n",
    "save_results_path_prefix = './../Dataset/'+TE_folder+'/Results/MLP_SD/'\n",
    "\n",
    "PF = np.load('./../Dataset/'+TE_folder+'/te_PF_smooth_LPBF_4.0.npz')['PF_smooth_LPBF']\n",
    "PF = PF[:, :11]\n",
    "\n",
    "AF = np.load('./../Dataset/'+TE_folder+'/te_'+AF_type+'.npz')[AF_type]\n",
    "N_features = AF.shape[1]\n",
    "\n",
    "SEGMENT_LEN = 300\n",
    "\n",
    "#######################\n",
    "# Load the dataset split  \n",
    "ds = np.load('./../Dataset/'+TE_folder+'/Dataset_split/split_masks_all.npz')\n",
    "test_mask  = ds['test_mask']\n",
    "\n",
    "X_test  = AF[test_mask]\n",
    "del AF\n",
    "Y_test  = PF[test_mask]\n",
    "del PF\n",
    "\n",
    "print X_test.shape\n",
    "\n",
    "offset = 0\n",
    "for VID, N_VID_samples in zip(test_VIDs, test_VIDs_ind_cnts):\n",
    "    \n",
    "    SID = VID[:5]\n",
    "    #print SID\n",
    "    \n",
    "    #######################\n",
    "    # Load best model for this SID\n",
    "    model_name = sorted(glob.glob( model_checkpoint_path_prefix + tuning_type + '/m_' + SID + '_*' ))[-1] # take best model = last checkpointed\n",
    "    test_model_name = model_name\n",
    "    print \"Loading BEST model from:\", test_model_name\n",
    "    model = load_model(test_model_name)\n",
    "    \n",
    "    ###############################################################################################################\n",
    "    # Predict on testing set\n",
    "    test_batch_size = len(X_test[offset:offset+N_VID_samples])\n",
    "    if offset == 0:\n",
    "        Y_test_pred = model.predict(X_test[offset:offset+N_VID_samples], batch_size=test_batch_size, verbose=1)\n",
    "    else:\n",
    "        pred = model.predict(X_test[offset:offset+N_VID_samples], batch_size=test_batch_size, verbose=1)\n",
    "        Y_test_pred = np.concatenate( (Y_test_pred, pred), axis=0)\n",
    "        \n",
    "    offset += N_VID_samples\n",
    "\n",
    "save_predictions_no_eval(save_results_path_prefix + 'WHOLEtest_MLP_SD', \n",
    "                         X_test, Y_test, Y_test_pred, 'MLP_SD', SEGMENT_LEN, test_VIDs, test_VIDs_ind_cnts, \n",
    "                        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test VIDs: ['PID18Task2' 'PID18Task3' 'PID23Task2' 'PID23Task3'] \n",
      "\n",
      "N_test_RT_seg: [4687 5871 5801 5031] \n",
      "\n",
      "(21390, 300, 26)\n",
      "Loading BEST model from: ./ModelCheckpoints/LSTM_SD/1_26_12_PID18/m_0500_0.0054_0.0047.hdf5\n",
      "4687/4687 [==============================] - 1s 152us/step\n",
      "Loading BEST model from: ./ModelCheckpoints/LSTM_SD/1_26_12_PID18/m_0500_0.0054_0.0047.hdf5\n",
      "5871/5871 [==============================] - 1s 148us/step\n",
      "Loading BEST model from: ./ModelCheckpoints/LSTM_SD/1_26_12_PID23/m_0500_0.0020_0.0020.hdf5\n",
      "5801/5801 [==============================] - 1s 145us/step\n",
      "Loading BEST model from: ./ModelCheckpoints/LSTM_SD/1_26_12_PID23/m_0500_0.0020_0.0020.hdf5\n",
      "5031/5031 [==============================] - 1s 164us/step\n",
      "Saved (raw & smoothed predictions WITHOUT results) to: ./../Dataset/TrainingExamples_16kHz/Results/LSTM_SD/WHOLEtest_LSTM_SD\n",
      "(21390, 26) (21390, 11) (21390, 11)\n"
     ]
    }
   ],
   "source": [
    "###############################################################################################################\n",
    "# LSTM\n",
    "###############################################################################################################\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import load_model\n",
    "from postprocessingutils import save_predictions_no_eval\n",
    "\n",
    "AF_type = 'AF_logFB26_norm'\n",
    "SEG_folder = 'Segments_logFB26'\n",
    "TE_folder = 'TrainingExamples_16kHz'\n",
    "# Load segmented data, already split\n",
    "X_test_RT = np.load('./../Dataset/'+TE_folder+'/' + SEG_folder + '/seg_test_RT.npz')['X'] \n",
    "Y_test_RT = np.load('./../Dataset/'+TE_folder+'/' + SEG_folder + '/seg_test_RT.npz')['Y'] \n",
    "test_VIDs =  np.load('./../Dataset/'+TE_folder+'/' + SEG_folder + '/seg_test.npz')['test_VIDs']\n",
    "print \"Test VIDs:\", test_VIDs, \"\\n\"\n",
    "N_test_RT_seg =  np.load('./../Dataset/'+TE_folder+'/' + SEG_folder + '/seg_test_RT.npz')['N_test_RT_seg']\n",
    "print \"N_test_RT_seg:\", N_test_RT_seg, \"\\n\"\n",
    "\n",
    "print X_test_RT.shape\n",
    "\n",
    "N_runs = 1\n",
    "SEGMENT_LEN = 300 # == X_train.shape[1]\n",
    "N_features = 26\n",
    "N_targets  = 11\n",
    "N_LSTM_units = 12 # BEST FOUND in LSTM_SI\n",
    "save_results_path_prefix = './../Dataset/'+TE_folder+'/Results/LSTM_SD/'\n",
    "model_checkpoint_path_prefix = './ModelCheckpoints/LSTM_SD/{:d}_{:d}_{:d}_'.format(N_runs, N_features, N_LSTM_units)\n",
    "\n",
    "\n",
    "offset = 0\n",
    "for VID, N_VID_samples in zip(test_VIDs, N_test_RT_seg):\n",
    "    \n",
    "    SID = VID[:5]\n",
    "    #print SID\n",
    "    \n",
    "    #######################\n",
    "    # Load best model for this SID\n",
    "    test_model_name = sorted(glob.glob(model_checkpoint_path_prefix + SID + '/m_*'))[-1]\n",
    "    print \"Loading BEST model from:\", test_model_name\n",
    "    model = load_model(test_model_name)\n",
    "    \n",
    "    ###############################################################################################################\n",
    "    # Predict on testing set\n",
    "    test_batch_size = len(X_test_RT[offset:offset+N_VID_samples])\n",
    "    \n",
    "    if offset == 0:\n",
    "        pred = model.predict(X_test_RT[offset:offset+N_VID_samples], batch_size=test_batch_size, verbose=1)\n",
    "        Y_test_pred = pred[:, -1, :] # last item from each segment is the (ONLINE) final prediction\n",
    "        Y_test_true = Y_test_RT[offset:offset+N_VID_samples, -1, :]\n",
    "        X_test_RT_last = X_test_RT[offset:offset+N_VID_samples, -1, :]\n",
    "    else:\n",
    "        pred = model.predict(X_test_RT[offset:offset+N_VID_samples], batch_size=test_batch_size, verbose=1)\n",
    "        pred = pred[:, -1, :]\n",
    "        Y_test_pred = np.concatenate( (Y_test_pred, pred), axis=0)\n",
    "        Y_test_true = np.concatenate( (Y_test_true, Y_test_RT[offset:offset+N_VID_samples, -1, :]), axis=0)\n",
    "        X_test_RT_last = np.concatenate( (X_test_RT_last, X_test_RT[offset:offset+N_VID_samples, -1, :]), axis=0)\n",
    "        \n",
    "    offset += N_VID_samples\n",
    "\n",
    "save_predictions_no_eval(save_results_path_prefix + 'WHOLEtest_LSTM_SD', \n",
    "                         X_test_RT_last, Y_test_true, Y_test_pred, 'LSTM_SD', SEGMENT_LEN, test_VIDs, N_test_RT_seg, \n",
    "                        )\n",
    "print X_test_RT_last.shape, Y_test_true.shape, Y_test_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
