{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################################################\n",
    "# Audio-driven upper-body motion synthesis on a humanoid robot\n",
    "# Computer Science Tripos Part III Project\n",
    "# Jan Ondras (jo356@cam.ac.uk), Trinity College, University of Cambridge\n",
    "# 2017/18\n",
    "#####################################################################################\n",
    "# Simulation of 3D pose reconstructed by the 3D pose estimation method OP+A\n",
    "# See below for implementation of domain-specific assumptions (A)\n",
    "#####################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VID: PID02Task2 ,\t #frames:  3815\n",
      "VID: PID02Task3 ,\t #frames:  3205\n",
      "VID: PID05Task2 ,\t #frames:  3810\n",
      "VID: PID05Task3 ,\t #frames:  3914\n",
      "VID: PID06Task2 ,\t #frames:  2947\n",
      "VID: PID06Task3 ,\t #frames:  3086\n",
      "VID: PID08Task2 ,\t #frames:  3275\n",
      "VID: PID08Task3 ,\t #frames:  3118\n",
      "VID: PID09Task2 ,\t #frames:  3484\n",
      "VID: PID09Task3 ,\t #frames:  3244\n",
      "VID: PID10Task2 ,\t #frames:  2458\n",
      "VID: PID10Task3 ,\t #frames:  2779\n",
      "VID: PID11Task2 ,\t #frames:  2424\n",
      "VID: PID11Task3 ,\t #frames:  3392\n",
      "VID: PID13Task2 ,\t #frames:  2482\n",
      "VID: PID13Task3 ,\t #frames:  1487\n",
      "VID: PID15Task2 ,\t #frames:  2344\n",
      "VID: PID15Task3 ,\t #frames:  3846\n",
      "VID: PID16Task2 ,\t #frames:  2014\n",
      "VID: PID16Task3 ,\t #frames:  1361\n",
      "VID: PID17Task2 ,\t #frames:  2602\n",
      "VID: PID17Task3 ,\t #frames:  2770\n",
      "VID: PID18Task2 ,\t #frames:  2344\n",
      "VID: PID18Task3 ,\t #frames:  2936\n",
      "VID: PID19Task2 ,\t #frames:  2554\n",
      "VID: PID19Task3 ,\t #frames:  2652\n",
      "VID: PID20Task2 ,\t #frames:  1302\n",
      "VID: PID20Task3 ,\t #frames:  2946\n",
      "VID: PID21Task2 ,\t #frames:  1753\n",
      "VID: PID21Task3 ,\t #frames:  1644\n",
      "VID: PID22Task2 ,\t #frames:  3348\n",
      "VID: PID22Task3 ,\t #frames:  3646\n",
      "VID: PID23Task2 ,\t #frames:  2901\n",
      "VID: PID23Task3 ,\t #frames:  2516\n",
      "VID: PID24Task2 ,\t #frames:  3582\n",
      "VID: PID24Task3 ,\t #frames:  3695\n",
      "Error: multiple people detected, in  ./../Dataset/OpenposePoseFeatures/PID24Task3/PID24Task3_000000003547_keypoints.json\n",
      "Error: multiple people detected, in  ./../Dataset/OpenposePoseFeatures/PID24Task3/PID24Task3_000000003548_keypoints.json\n",
      "VID: PID25Task2 ,\t #frames:  4041\n",
      "VID: PID25Task3 ,\t #frames:  2520\n",
      "VID: PID26Task2 ,\t #frames:  2180\n",
      "VID: PID26Task3 ,\t #frames:  1838\n",
      "Done for all:  40\n"
     ]
    }
   ],
   "source": [
    "#######################################################################################################\n",
    "# Using 2D Openpose joints' locations AND constraints/assumptions => Lift to 3D\n",
    "# Save as 1 matrix: #frames x #joints x 3 for each VID\n",
    "# Done for all VIDs\n",
    "#######################################################################################################\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import savemat\n",
    "import json\n",
    "import os\n",
    "import glob\n",
    "from geo import *\n",
    "\n",
    "# Load 2D data for one VID \n",
    "#VID = 'PID20Task2'\n",
    "\n",
    "# openpose_COCO_joints = \n",
    "# \t      {0,  \"Nose\"},\n",
    "#         {1,  \"Neck\"},\n",
    "#         {2,  \"RShoulder\"},\n",
    "#         {3,  \"RElbow\"},\n",
    "#         {4,  \"RWrist\"},\n",
    "#         {5,  \"LShoulder\"},\n",
    "#         {6,  \"LElbow\"},\n",
    "#         {7,  \"LWrist\"},\n",
    "#         {8,  \"RHip\"},\n",
    "#         {9,  \"RKnee\"},\n",
    "#         {10, \"RAnkle\"},\n",
    "#         {11, \"LHip\"},\n",
    "#         {12, \"LKnee\"},\n",
    "#         {13, \"LAnkle\"},\n",
    "#            \t{14, \"REye\"},\n",
    "#           \t{15, \"LEye\"},\n",
    "#           \t{16, \"REar\"},\n",
    "#           \t{17, \"LEar\"},\n",
    "#           \t{18, \"Background\"} # not included in JSON files => 18 joints in total\n",
    "\n",
    "N_joints = 18\n",
    "# joints_used = [0,1,2,3,4,5,6,7,8, 11] # first 14 from COCO model, w/o legs => 10\n",
    "jointID = {     # Mapping: joint names -> position in array as extracted\n",
    "    'RHip'      : 8,    \n",
    "    'LHip'      : 11,   \n",
    "    'Neck'      : 1,\n",
    "    'HeadTop'   : 0,  \n",
    "    'LShoulder' : 5,\n",
    "    'LElbow'    : 6,\n",
    "    'LWrist'    : 7,\n",
    "    'RShoulder' : 2,\n",
    "    'RElbow'    : 3,\n",
    "    'RWrist'    : 4\n",
    "}\n",
    "\n",
    "cnt = 0\n",
    "for dir_path in sorted(glob.glob('./../Dataset/OpenposePoseFeatures/*')):\n",
    "\n",
    "    VID = dir_path.split('/')[-1]\n",
    "\n",
    "    json_filenames = sorted(glob.glob('./../Dataset/OpenposePoseFeatures/' + VID + '/*.json'))\n",
    "    # print (json_filenames[0])\n",
    "    # print (json_filenames[-1])\n",
    "    print( 'VID:', VID, ',\\t #frames: ', len(json_filenames)) # 1302\n",
    "    N_frames = len(json_filenames)\n",
    "\n",
    "    # Array for this VID: #frames x #joints x 3\n",
    "    joints_3D = np.zeros( (N_frames, N_joints, 3) )\n",
    "\n",
    "    # Limb lengths constants (might be adaptively updated if longer found)\n",
    "    C1 = 0. \n",
    "    R2 = 0. \n",
    "    R3 = 0. \n",
    "    L2 = 0. \n",
    "    L3 = 0. \n",
    "\n",
    "    # Load: iterate over all frames IN ORDER ! IT IS IMPORTANT THAT IT IS SORTED !!!\n",
    "    for i, json_filename in enumerate(json_filenames): \n",
    "        data = json.load(open(json_filename))\n",
    "        if len(data['people']) != 1:\n",
    "            print (\"Error: multiple people detected, in \", json_filename) # but it's ok, always first one is the correct person detected - I checked manually\n",
    "\n",
    "        f = np.reshape(data['people'][0]['pose_keypoints'], (-1,3)) # matrix = #joints x 3 (x,y,score)\n",
    "        # print (len(f))\n",
    "        # print (f)\n",
    "        # f = f[joints_used] # keeping only 14 joints\n",
    "        joints_3D[i, :, :2] = f[:, [0,1]] # copy only x, y, omit score; array joints_3D has now z=0 for all joints\n",
    "\n",
    "        #################################################\n",
    "        # Update (if necessary) current estimates of limb lengths\n",
    "        C1m = Point(joints_3D[i, jointID['Neck']]).distance_to(Point(joints_3D[i, jointID['HeadTop']])) # measured in current frame\n",
    "        C1 = max(C1, C1m) # maximum sofar - assumed to be actual limb length\n",
    "\n",
    "        R2m = Point(joints_3D[i, jointID['RShoulder']]).distance_to(Point(joints_3D[i, jointID['RElbow']])) # measured in current frame\n",
    "        R2 = max(R2, R2m) # maximum sofar - assumed to be actual limb length\n",
    "\n",
    "        R3m = Point(joints_3D[i, jointID['RElbow']]).distance_to(Point(joints_3D[i, jointID['RWrist']])) # measured in current frame\n",
    "        R3 = max(R3, R3m) # maximum sofar - assumed to be actual limb length\n",
    "\n",
    "        L2m = Point(joints_3D[i, jointID['LShoulder']]).distance_to(Point(joints_3D[i, jointID['LElbow']])) # measured in current frame\n",
    "        L2 = max(L2, L2m) # maximum sofar - assumed to be actual limb length\n",
    "\n",
    "        L3m = Point(joints_3D[i, jointID['LElbow']]).distance_to(Point(joints_3D[i, jointID['LWrist']])) # measured in current frame\n",
    "        L3 = max(L3, L3m) # maximum sofar - assumed to be actual limb length\n",
    "\n",
    "        #################################################\n",
    "        # Lift z coordinates of joints: HeadTop, RElbow, RWrist, LElbow, LWrist; others z = 0\n",
    "\n",
    "        joints_3D[i, jointID['HeadTop'], 2] = np.sqrt( (C1**2) - (C1m**2) )\n",
    "\n",
    "        joints_3D[i, jointID['RElbow'],  2] = np.sqrt( (R2**2) - (R2m**2) )\n",
    "        joints_3D[i, jointID['LElbow'],  2] = np.sqrt( (L2**2) - (L2m**2) )\n",
    "\n",
    "        joints_3D[i, jointID['RWrist'],  2] = joints_3D[i, jointID['RElbow'],  2] + np.sqrt( (R3**2) - (R3m**2) )\n",
    "        joints_3D[i, jointID['LWrist'],  2] = joints_3D[i, jointID['LElbow'],  2] + np.sqrt( (L3**2) - (L3m**2) )\n",
    "\n",
    "        joints_3D[i, :, 2] *= -1. # correct orientation\n",
    "\n",
    "\n",
    "    #######################################################################################################\n",
    "    # Save 3D joints, one file per VID\n",
    "\n",
    "    np.savez('./../Dataset/OpenPoseConstraintsFeatures/' +VID+ '.npz', joints_3D=joints_3D)\n",
    "\n",
    "    cnt += 1\n",
    "\n",
    "print (\"Done for all: \", cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape = (2516, 18, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div id=\"glowscript\" class=\"glowscript\"></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "window.__context = { glowscript_container: $(\"#glowscript\").removeAttr(\"id\")}"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#########################################################################################################\n",
    "# Render in 3D\n",
    "# and show on robot\n",
    "#########################################################################################################\n",
    "\n",
    "from geoutils import radToDeg, xyz_to_angles\n",
    "from vpython import *\n",
    "from scipy.io import loadmat\n",
    "import numpy as np\n",
    "from geo import *\n",
    "\n",
    "VID = 'PID20Task2'\n",
    "VID = 'PID23Task3'\n",
    "\n",
    "STOP_AT_FRAMES = [1360, 1375, 1390]\n",
    "STOP_AT_FRAMES = [1375, 1390]\n",
    "STOP_AT_FRAMES = [1390]\n",
    "STOP_AT_FRAMES = [1]\n",
    "\n",
    "show_labels = True\n",
    "# show_labels = False\n",
    "\n",
    "# smooth_joints_pos = True # not done \n",
    "smooth_joints_pos = False\n",
    "\n",
    "FR = 1000\n",
    "FR = 10\n",
    "\n",
    "#################################################\n",
    "showRobot = True # simultaneously send commands to the robot\n",
    "showRobot = False\n",
    "\n",
    "angles_names = [\n",
    "    \"HeadPitch\", \"HeadYaw\", \n",
    "    \"LShoulderRoll\", \"LShoulderPitch\", \"LElbowRoll\", \"LElbowYaw\",\n",
    "    \"RShoulderRoll\", \"RShoulderPitch\", \"RElbowRoll\", \"RElbowYaw\", \n",
    "    \"HipRoll\", \"HipPitch\"\n",
    "]\n",
    "if showRobot:\n",
    "    print (\"Showing on virtual robot ...\")\n",
    "    from naoqi import ALProxy\n",
    "    IP = \"127.0.0.1\"\n",
    "    port = 45637\n",
    "    motionProxy = ALProxy(\"ALMotion\", IP, port)\n",
    "    # Reset robot to neutral pose\n",
    "    for an in angles_names:\n",
    "        angle_reset = 0.\n",
    "        if an == 'LShoulderPitch' or an == 'RShoulderPitch':\n",
    "            angle_reset = angle_reset + np.pi/2\n",
    "        motionProxy.setAngles(an, angle_reset, 1.)\n",
    "        \n",
    "    jointID = {     # Mapping: joint names -> position in array as extracted\n",
    "        #'Pelvis'    : NA,  # not available => have to estimate from hips\n",
    "        'RHip'      : 8,    \n",
    "        'LHip'      : 11,   \n",
    "        #'Spine'     : NA,  # not available, not used\n",
    "        'Neck'      : 1,\n",
    "        #'Nose'      : NA,  # not available => have to estimate HeadYaw another way\n",
    "        'HeadTop'   : 0,  \n",
    "        'LShoulder' : 5,\n",
    "        'LElbow'    : 6,\n",
    "        'LWrist'    : 7,\n",
    "        'RShoulder' : 2,\n",
    "        'RElbow'    : 3,\n",
    "        'RWrist'    : 4\n",
    "    }\n",
    "#################################################\n",
    "\n",
    "# joints_used = np.arange(17) # first 17\n",
    "joints_used = [0,1,2,3,4,5,6,7, 8, 11] # 14 from COCO model, w/o legs, eyes, ears\n",
    "\n",
    "joints_names = ['head_top','neck','right_shoulder','right_elbow','right_wrist',\n",
    "                'left_shoulder','left_elbow','left_wrist',\n",
    "                'right_hip','right_knee','right_ankle',\n",
    "                'left_hip','left_knee','left_ankle',\n",
    "                'right_eye','left_eye','right_ear', 'left_ear']\n",
    "joint_connections = [\n",
    "    (0, 1),                                                          # central, blue\n",
    "    (1,8), (1,11),                                                   # extra for Openpose\n",
    "    (1, 2), (2, 3), (3, 4), (8, 9), (9, 10), (0, 14), (14, 16),      # right, red\n",
    "    (1, 5), (5, 6), (6, 7), (11, 12), (12, 13), (0, 15), (15, 17)    # left, green\n",
    "]\n",
    "joint_connections_colors = [color.blue]*3 + [color.red]*7 + [color.green]*7\n",
    "joints_colors = [color.white]*len(joints_names)\n",
    "\n",
    "if smooth_joints_pos:\n",
    "#     data = np.load('./../Dataset/OpenPoseConstraintsFeatures_smoothed/' + VID + '.npz')['joints_3D']\n",
    "    print \"TODO\"\n",
    "    pass\n",
    "else:\n",
    "    data = np.load('./../Dataset/OpenPoseConstraintsFeatures/' + VID + '.npz')['joints_3D']\n",
    "\n",
    "print (\"Shape =\" , np.shape(data))\n",
    "\n",
    "# Setup scene\n",
    "scene = canvas()\n",
    "scene.width = 960\n",
    "scene.height = 600\n",
    "scene.title = \"Openpose 3D pose reconstruction using Constraints and assumptions\"\n",
    "scene.scale = 400.\n",
    "# scene.fov = np.pi /3.\n",
    "scene.up=vector(0.,-1.,0.)     # To flip scene horiznotally !!!\n",
    "scene.forward=vector(0.,0.,1.)     # To rotate around y !!!\n",
    "# scene.center=vector(0.,-150.,10000) # To shift down a but\n",
    "\n",
    "###################################### Centering to neck joint\n",
    "data[0, :, :] = data[0, :, :] - data[0, 1, :]\n",
    "# data[:,:,2] = 0. # if you remove depth\n",
    "\n",
    "scene.lights = []\n",
    "scene.ambient=color.gray(0.8)\n",
    "\n",
    "# Texture uderneath\n",
    "y_plane_pos = 500\n",
    "plane_size = 1000\n",
    "# a = vertex( pos=vector(-plane_size, y_plane_pos, -plane_size) )\n",
    "# b = vertex( pos=vector(-plane_size, y_plane_pos,  plane_size) )\n",
    "# c = vertex( pos=vector( plane_size, y_plane_pos,  plane_size) )\n",
    "# d = vertex( pos=vector( plane_size, y_plane_pos, -plane_size) )\n",
    "# quad(vs=[a,b,c,d], texture=textures.rug)\n",
    "\n",
    "# SHOW PLANE UNDERNEATH THE FIGURE\n",
    "#box(pos=vec(0,y_plane_pos,0), length=plane_size, height=1, width=plane_size, texture=textures.rough)\n",
    "\n",
    "frame = 0\n",
    "scene.caption = 'Frame: ' + str(frame)\n",
    "Ps = []\n",
    "Es = []\n",
    "Ls = []\n",
    "# Draw all joints requested\n",
    "for i in joints_used:\n",
    "    x = data[frame, i, 0] #- skeleton_center[0]\n",
    "    y = data[frame, i, 1] #- skeleton_center[1]\n",
    "    z = data[frame, i, 2] #- skeleton_center[2]\n",
    "    P = sphere(pos=vector(x,y,z), radius=10, color=joints_colors[i])#, #size_units=\"world\")\n",
    "    Ps.append(P)\n",
    "    if show_labels:\n",
    "        L = label(pos=vector(x,y,z),\n",
    "                text=joints_names[i], xoffset=20,\n",
    "                yoffset=50, space=30,\n",
    "                height=16, border=3,\n",
    "                font='sans')\n",
    "        Ls.append(L)\n",
    "\n",
    "# Draw all links between joints\n",
    "for i, (a,b) in enumerate(joint_connections):\n",
    "    if a in joints_used and b in joints_used:\n",
    "        ax = data[frame, a, 0] #- skeleton_center[0]\n",
    "        ay = data[frame, a, 1] #- skeleton_center[1]\n",
    "        az = data[frame, a, 2] #- skeleton_center[2]\n",
    "        bx = data[frame, b, 0] #- skeleton_center[0]\n",
    "        by = data[frame, b, 1] #- skeleton_center[1]\n",
    "        bz = data[frame, b, 2] #- skeleton_center[2]\n",
    "        cx = (ax + bx) / 2.\n",
    "        cy = (ay + by) / 2.\n",
    "        cz = (az + bz) / 2.\n",
    "        E = ellipsoid(pos=vector(cx,cy,cz), axis=vector(ax-bx,ay-by,az-bz), length=np.linalg.norm([ax-bx,ay-by,az-bz]), \n",
    "                  height=25, width=25, color=joint_connections_colors[i])\n",
    "        Es.append(E)\n",
    "\n",
    "\n",
    "# Animate\n",
    "for frame in range(1, len(data)):\n",
    "    \n",
    "    ####################################################################\n",
    "    # Calculate joint angles & Send commands to the robot\n",
    "    if showRobot:\n",
    "        xyz = data[frame]\n",
    "        ####################################################################\n",
    "        # Calculate 12 joint angles, if not possible for this method set NAN (np.nan)\n",
    "        # xyz[jointID['Pelvis']] gives xyz coordinates of Pelvis joint\n",
    "        # For OP+C, pass None for Nose position => can only estimate HeadYaw\n",
    "        # And estimate Pelvis position as midpoint of LHip-RHip\n",
    "        PE = Point(xyz[jointID['LHip']]).midpoint_to(Point(xyz[jointID['RHip']]))\n",
    "\n",
    "        jas = xyz_to_angles(Point(xyz[jointID['HeadTop']]), None, \n",
    "                            Point(xyz[jointID['Neck']]),    PE, \n",
    "                    Point(xyz[jointID['LShoulder']]), Point(xyz[jointID['LElbow']]), Point(xyz[jointID['LWrist']]), \n",
    "                    Point(xyz[jointID['RShoulder']]), Point(xyz[jointID['RElbow']]), Point(xyz[jointID['RWrist']])                  \n",
    "        )\n",
    "        \n",
    "        for ang_ind, ang in enumerate(jas):\n",
    "            if not np.isnan(ang): # take only angles available for this method\n",
    "                motionProxy.setAngles(angles_names[ang_ind], ang, 1.)\n",
    "    \n",
    "    ###################################### Centering to neck joint\n",
    "    data[frame, :, :] = data[frame, :, :] - data[frame, 1, :]\n",
    "    \n",
    "    rate(FR)\n",
    "    scene.caption = 'Frame: ' + str(frame)\n",
    "    # Draw all joints requested\n",
    "    cnt = 0\n",
    "    for i in joints_used:\n",
    "        x = data[frame, i, 0] #- skeleton_center[0]\n",
    "        y = data[frame, i, 1] #- skeleton_center[1]\n",
    "        z = data[frame, i, 2] #- skeleton_center[2]\n",
    "        Ps[cnt].pos = vector(x,y,z)\n",
    "        if show_labels:\n",
    "            Ls[cnt].pos = vector(x,y,z)\n",
    "        cnt += 1\n",
    "\n",
    "    # Draw all links between joints\n",
    "    cnt = 0\n",
    "    for i, (a,b) in enumerate(joint_connections):\n",
    "        if a in joints_used and b in joints_used:\n",
    "            ax = data[frame, a, 0] #- skeleton_center[0]\n",
    "            ay = data[frame, a, 1] #- skeleton_center[1]\n",
    "            az = data[frame, a, 2] #- skeleton_center[2]\n",
    "            bx = data[frame, b, 0] #- skeleton_center[0]\n",
    "            by = data[frame, b, 1] #- skeleton_center[1]\n",
    "            bz = data[frame, b, 2] #- skeleton_center[2]    \n",
    "            cx = (ax + bx) / 2.\n",
    "            cy = (ay + by) / 2.\n",
    "            cz = (az + bz) / 2.\n",
    "            Es[cnt].pos = vector(cx,cy,cz)\n",
    "            Es[cnt].axis = vector(ax-bx,ay-by,az-bz)\n",
    "            Es[cnt].length = np.linalg.norm([ax-bx,ay-by,az-bz])\n",
    "            cnt += 1\n",
    "\n",
    "    if frame in STOP_AT_FRAMES:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VPython",
   "language": "python",
   "name": "vpython"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
