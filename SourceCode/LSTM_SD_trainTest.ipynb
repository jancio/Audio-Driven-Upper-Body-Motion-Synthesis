{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################################################\n",
    "# Audio-driven upper-body motion synthesis on a humanoid robot\n",
    "# Computer Science Tripos Part III Project\n",
    "# Jan Ondras (jo356@cam.ac.uk), Trinity College, University of Cambridge\n",
    "# 2017/18\n",
    "#####################################################################################\n",
    "# Training, validation and testing of the LSTM-SI model\n",
    "#####################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################################################\n",
    "# LSTM Training and testing\n",
    "# PER SUBJECT\n",
    "###############################################################################################################\n",
    "# Load segmented data, already split\n",
    "# NOT Rescale target angles to range [0,1] (already done when segmenting)\n",
    "###############################################################################################################\n",
    "\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import time\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Masking, TimeDistributed, Dropout\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "np.random.seed(37) # for reproducibility\n",
    "\n",
    "AF_type = 'AF_logFB26_norm'\n",
    "SEG_folder = 'Segments_logFB26'\n",
    "TE_folder = 'TrainingExamples_16kHz'\n",
    "unique_srt_VIDs = np.load('./../Dataset/'+TE_folder+'/te_unique_srt_VIDs.npz')['unique_srt_VIDs'] # sorted VIDs\n",
    "all_srt_VIDs = np.load('./../Dataset/'+TE_folder+'/te_VIDs.npz')['VIDs']\n",
    "unique_srt_SIDs = np.array([x[:5] for i, x in enumerate(unique_srt_VIDs) if i % 2 == 0]) # ['PID02', 'PID05', ..\n",
    "\n",
    "# Best LSTM architecture from LSTM SI; no dropout\n",
    "N_runs = 1\n",
    "SEGMENT_LEN = 300 # == X_train.shape[1]\n",
    "N_epochs = 500                    # this value is saved as N_epochs\n",
    "# train_batch_size = 15000 # same for all models; for LOGFB26 and also for MFCC13\n",
    "N_features = 26\n",
    "N_targets  = 11\n",
    "N_LSTM_units = 12 # BEST FOUND in LSTM_SI\n",
    "useDropout = False\n",
    "\n",
    "model_checkpoint_path_prefix = './ModelCheckpoints/LSTM_SD/'\n",
    "save_training_hist_path_prefix = './../Dataset/'+TE_folder+'/Results/LSTM_SD/trainHistES_' # ES = early stop\n",
    "\n",
    "# Train model for each subject\n",
    "st = time.time()\n",
    "for s, SID in enumerate(unique_srt_SIDs):\n",
    "\n",
    "    print SID\n",
    "\n",
    "    ######################################################################################################\n",
    "    # Load segmented data, already split\n",
    "    ds = np.load('./../Dataset/'+TE_folder+'/' + SEG_folder + '/perSID/seg_' + SID + '.npz')\n",
    "\n",
    "    X_train = ds['X_train'] \n",
    "    Y_train = ds['Y_train'] \n",
    "\n",
    "    X_val = ds['X_val'] \n",
    "    Y_val = ds['Y_val'] \n",
    "\n",
    "    X_val_RT = ds['X_val_RT'] \n",
    "    Y_val_RT = ds['Y_val_RT'] \n",
    "\n",
    "    X_test = ds['X_test'] \n",
    "    Y_test = ds['Y_test'] \n",
    "\n",
    "    X_test_RT = ds['X_test_RT'] \n",
    "    Y_test_RT = ds['Y_test_RT'] \n",
    "\n",
    "    N_train_seg =    ds['N_train_seg']\n",
    "    N_val_seg =      ds['N_val_seg']\n",
    "    N_val_RT_seg =   ds['N_val_RT_seg']\n",
    "    N_test_seg =     ds['N_test_seg']\n",
    "    N_test_RT_seg =  ds['N_test_RT_seg']\n",
    "\n",
    "    ######################################################################################################\n",
    "    # TRAIN & VALIDATE: save best model and training history\n",
    "    # Sequence tagging approach (LSTMs)\n",
    "    # if all feature values at a timestep are equal to mask_value=0., then the timestep is skipped\n",
    "\n",
    "    train_batch_size = X_train.shape[0] # for N_LSTM_units = 128 and less\n",
    "    print(\"\\tTrain batch size: {:d}\".format(train_batch_size))\n",
    "\n",
    "    # SET MODEL TYPE\n",
    "    model_type = '{:d}_{:d}_{:02d}_{:}'.format(N_runs, N_features, N_LSTM_units, SID)\n",
    "    print \"\\tMODEL TYPE:\\t\\t\", model_type\n",
    "    if not os.path.isdir(model_checkpoint_path_prefix + model_type):\n",
    "        os.mkdir(model_checkpoint_path_prefix + model_type)\n",
    "\n",
    "    # Create LSTM model\n",
    "    model = Sequential()\n",
    "    model.add( Masking(mask_value=0., input_shape=(SEGMENT_LEN, N_features)) )\n",
    "    if useDropout:\n",
    "        model.add( Dropout(dropouts[0]) )\n",
    "    model.add( LSTM(N_LSTM_units, return_sequences=True) )\n",
    "    if useDropout:\n",
    "        model.add( Dropout(dropouts[1]) )    \n",
    "    model.add( TimeDistributed(Dense(N_targets, activation='sigmoid')) )\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    #print model.summary()\n",
    "\n",
    "    # Set early stopping\n",
    "    early_stop = EarlyStopping(monitor='val_loss', patience=10, verbose=1)\n",
    "\n",
    "    # Checkpoint model weights and the model itself: at each epoch\n",
    "    model_checkpoint_name = 'm_{epoch:04d}_{loss:.4f}_{val_loss:.4f}.hdf5'\n",
    "    model_checkpoint = ModelCheckpoint(model_checkpoint_path_prefix + model_type + '/' + model_checkpoint_name, monitor='val_loss', verbose=0, \n",
    "                                       save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "\n",
    "    loss = []\n",
    "    val_loss = []\n",
    "    for i in range(N_runs):\n",
    "        # Tain & validate\n",
    "        hist = model.fit(X_train, Y_train, validation_data=(X_val, Y_val), epochs=N_epochs, shuffle=True,  \n",
    "                         batch_size=train_batch_size, verbose=0, \n",
    "                         callbacks=[early_stop, model_checkpoint]\n",
    "                        )\n",
    "        loss.append( hist.history['loss'] )\n",
    "        val_loss.append( hist.history['val_loss'] )\n",
    "    # Save training history\n",
    "    np.savez(save_training_hist_path_prefix + model_type + '.npz', \n",
    "            loss=loss, val_loss=val_loss, \n",
    "            N_params=model.count_params(), train_batch_size=train_batch_size, \n",
    "            N_runs=N_runs, N_LSTM_units=N_LSTM_units, N_epochs=N_epochs)\n",
    "    print \"\\tEarly stop at epoch:\", len(hist.history['loss'])\n",
    "    print \"\\tSaved training history: \", save_training_hist_path_prefix + model_type + '.npz'\n",
    "    print \"\\tBest model saved to: \", model_checkpoint_path_prefix + model_type + '/' + model_checkpoint_name\n",
    "    print \"\\tTime taken: \", time.time()-st, (time.time()-st)/60.  \n",
    "    \n",
    "# All: Time taken:  3285.47157311 54.7578600009\n",
    "# all 250 min, for 500 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################################################################\n",
    "# Evaluate on VALIDATION & TEST SET;\n",
    "# save results\n",
    "# DONE\n",
    "######################################################################################################\n",
    "from postprocessingutils import save_predictions_and_eval\n",
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import time\n",
    "\n",
    "np.random.seed(37) # for reproducibility\n",
    "\n",
    "AF_type = 'AF_logFB26_norm'\n",
    "SEG_folder = 'Segments_logFB26'\n",
    "TE_folder = 'TrainingExamples_16kHz'\n",
    "unique_srt_VIDs = np.load('./../Dataset/'+TE_folder+'/te_unique_srt_VIDs.npz')['unique_srt_VIDs'] # sorted VIDs\n",
    "all_srt_VIDs = np.load('./../Dataset/'+TE_folder+'/te_VIDs.npz')['VIDs']\n",
    "unique_srt_SIDs = np.array([x[:5] for i, x in enumerate(unique_srt_VIDs) if i % 2 == 0]) # ['PID02', 'PID05', ..\n",
    "\n",
    "# Best LSTM architecture from LSTM SI; no dropout\n",
    "N_runs = 1\n",
    "SEGMENT_LEN = 300 # == X_train.shape[1]\n",
    "N_features = 26\n",
    "N_targets  = 11\n",
    "N_LSTM_units = 12 # BEST FOUND in LSTM_SI\n",
    "\n",
    "save_results_path_prefix = './../Dataset/'+TE_folder+'/Results/LSTM_SD/'\n",
    "model_checkpoint_path_prefix = './ModelCheckpoints/LSTM_SD/{:d}_{:d}_{:d}_'.format(N_runs, N_features, N_LSTM_units)\n",
    "\n",
    "# Evaluate for each subject\n",
    "st = time.time()\n",
    "for s, SID in enumerate(unique_srt_SIDs):\n",
    "\n",
    "    print SID\n",
    "    \n",
    "    #########################################\n",
    "    # Load trained model for this SID\n",
    "    test_model_name = sorted(glob.glob(model_checkpoint_path_prefix + SID + '/m_*'))[-1]\n",
    "    N_epochs = int( (test_model_name.split('/')[-1]).split('_')[1] )\n",
    "    print \"\\t Loaded model:\", test_model_name\n",
    "    print \"\\t # epochs:\", N_epochs\n",
    "    model = load_model( test_model_name )\n",
    "    \n",
    "    ######################################################################################################\n",
    "    # Load segmented data, already split\n",
    "    ds = np.load('./../Dataset/'+TE_folder+'/' + SEG_folder + '/perSID/seg_' + SID + '.npz')\n",
    "\n",
    "    X_val_RT = ds['X_val_RT'] \n",
    "    Y_val_RT = ds['Y_val_RT'] \n",
    "\n",
    "    X_test_RT = ds['X_test_RT'] \n",
    "    Y_test_RT = ds['Y_test_RT'] \n",
    "\n",
    "    N_val_RT_seg =   ds['N_val_RT_seg']\n",
    "    N_test_RT_seg =  ds['N_test_RT_seg']\n",
    "    \n",
    "    #######################\n",
    "    # Load the dataset split (for this SID); concat from both VIDs\n",
    "    ds1 = np.load('./../Dataset/'+TE_folder+'/Dataset_split/split_masks_' + SID  + 'Task2.npz')\n",
    "    ds2 = np.load('./../Dataset/'+TE_folder+'/Dataset_split/split_masks_' + SID  + 'Task3.npz')\n",
    "\n",
    "    ###############################################################################################################\n",
    "    # Evaluate on validation set\n",
    "    # ONLINE TESTING (as if new timesteps arrive one-by-one)\n",
    "    \n",
    "    val_batch_size = X_val_RT.shape[0]\n",
    "    Y_val_pred = model.predict(X_val_RT, batch_size=val_batch_size, verbose=1)  \n",
    "    Y_val_pred = Y_val_pred[:, -1, :] # last item from each segment is the (ONLINE) final prediction\n",
    "    Y_val_true = Y_val_RT[:, -1, :]\n",
    "    X_val_RT_last = X_val_RT[:, -1, :]\n",
    "    print X_val_RT.shape, X_val_RT_last.shape, Y_val_pred.shape, Y_val_true.shape\n",
    "    \n",
    "    # Save results: predictions will be saved in radians; for generation on robot\n",
    "    # Raw and smoothed (low-pass 4Hz)\n",
    "    val_VIDs = [SID + 'Task2', SID + 'Task3']\n",
    "    SD_offsets = [len(ds1['train_mask']), len(ds2['train_mask']) ]\n",
    "    \n",
    "    if N_val_RT_seg[0] != len(ds1['val_mask']) or N_val_RT_seg[1] != len(ds2['val_mask']):\n",
    "        raise ValueError('PROBLEM!!!')\n",
    "    \n",
    "    save_predictions_and_eval(save_results_path_prefix + 'MSBMvaltest_{:d}_{:d}_{:d}_{:}'.format(N_runs, N_features, N_LSTM_units, SID), \n",
    "                     X_val_RT_last, Y_val_true, Y_val_pred, 'LSTM_SD', SEGMENT_LEN, val_VIDs, N_val_RT_seg, \n",
    "                            SD_offsets, \n",
    "                             N_params=model.count_params(), N_epochs=N_epochs  )\n",
    "    \n",
    "    ###############################################################################################################\n",
    "    # Evaluate on testing set: \n",
    "    # ONLINE TESTING (as if new timesteps arrive one-by-one)\n",
    "    \n",
    "    test_batch_size = X_test_RT.shape[0]\n",
    "    Y_test_pred = model.predict(X_test_RT, batch_size=test_batch_size, verbose=1)\n",
    "    Y_test_pred = Y_test_pred[:, -1, :] # last item from each segment is the (ONLINE) final prediction\n",
    "    Y_test_true = Y_test_RT[:, -1, :]\n",
    "    X_test_RT_last = X_test_RT[:, -1, :]\n",
    "    print X_test_RT.shape, X_test_RT_last.shape, Y_test_pred.shape, Y_test_true.shape\n",
    "\n",
    "    # Save results: predictions will be saved in radians; for generation on robot\n",
    "    # Raw and smoothed (low-pass 4Hz)\n",
    "    test_VIDs = [SID + 'Task2', SID + 'Task3']\n",
    "    SD_offsets = [len(ds1['train_mask']) + len(ds1['val_mask']), len(ds2['train_mask']) + len(ds2['val_mask'])]\n",
    "    save_predictions_and_eval(save_results_path_prefix + 'MSBMtest_{:d}_{:d}_{:d}_{:}'.format(N_runs, N_features, N_LSTM_units, SID), \n",
    "                     X_test_RT_last, Y_test_true, Y_test_pred, 'LSTM_SD', SEGMENT_LEN, test_VIDs, N_test_RT_seg, \n",
    "                              SD_offsets,\n",
    "                              N_params=model.count_params(), N_epochs=N_epochs )       \n",
    "    \n",
    "    print \"\\tTime taken: \", time.time()-st, (time.time()-st)/60.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy the best model for each subject\n",
    "# DONE\n",
    "\n",
    "from shutil import copy2\n",
    "\n",
    "model_checkpoint_path_prefix = './ModelCheckpoints/LSTM_SD/{:d}_{:d}_{:d}_'.format(N_runs, N_features, N_LSTM_units)\n",
    "\n",
    "for s, SID in enumerate(unique_srt_SIDs):\n",
    "    test_model_name = sorted(glob.glob(model_checkpoint_path_prefix + SID + '/m_*'))[-1]   \n",
    "    new_name = model_checkpoint_path_prefix + SID + '_' + test_model_name.split('/')[-1]\n",
    "    copy2(test_model_name, new_name)\n",
    "    print new_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
